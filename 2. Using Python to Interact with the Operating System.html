<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>2. Using Python to Interact with the Operating System</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__left">
    <div class="stackedit__toc">
      
<ul>
<li><a href="#using-python-to-interact-with-the-operating-system">2. Using Python to Interact with the Operating System</a>
<ul>
<li><a href="#course-introduction">Course Introduction</a>
<ul>
<li><a href="#finding-out-more-information">Finding out more information</a></li>
<li><a href="#getting-familiar-with-the-operating-system">Getting Familiar with the Operating System</a></li>
<li><a href="#getting-your-computer-ready-for-python">Getting Your Computer Ready for Python</a></li>
<li><a href="#pointers-for-getting-your-environment-setup">Pointers for Getting Your Environment Setup</a>
<ul>
<li><a href="#learning-more-about-operating-systems">Learning more about operating systems</a></li>
<li><a href="#installing-python-and-additional-modules">Installing Python and additional modules</a></li>
<li><a href="#using-package-management-systems">Using package management systems</a></li>
<li><a href="#other-information">Other information</a></li>
</ul>
</li>
<li><a href="#running-python-locally">Running Python Locally</a>
<ul>
<li><a href="#interpreted-vs.-compiled-languages">Interpreted vs. Compiled Languages</a></li>
<li><a href="#how-to-run-a-python-script">How to Run a Python Script</a></li>
<li><a href="#setting-up-your-environment">Setting up Your Environment</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#automating-tasks-through-programming">Automating Tasks Through Programming</a>
<ul>
<li><a href="#benefits-of-automation">Benefits of Automation</a></li>
<li><a href="#pitfalls-of-automation">Pitfalls of Automation</a>
<ul>
<li><a href="#is-it-worth-the-time">Is it worth the time?</a></li>
</ul>
</li>
<li><a href="#practical-automation-example">Practical Automation Example</a></li>
</ul>
</li>
<li><a href="#reading-and-writing-files">Reading and Writing Files</a>
<ul>
<li><a href="#programming-with-files">Programming with Files</a></li>
<li><a href="#reading-files">Reading Files</a>
<ul>
<li><a href="#the-open-use-close-approach">The “Open-Use-Close” Approach</a></li>
<li><a href="#the-with-approach">The “With” Approach</a></li>
</ul>
</li>
<li><a href="#iterating-through-files">Iterating through Files</a></li>
<li><a href="#writing-files">Writing Files</a>
<ul>
<li><a href="#notion-of-file-modes-see-cheat-sheet-below">Notion of file modes (see Cheat-Sheet below)</a></li>
</ul>
</li>
<li><a href="#reading-and-writing-files-cheat-sheet">Reading and Writing Files Cheat-Sheet</a></li>
</ul>
</li>
<li><a href="#managing-files-and-directories">Managing Files and Directories</a>
<ul>
<li><a href="#working-with-files">Working with Files</a></li>
<li><a href="#more-file-information">More File Information</a></li>
<li><a href="#directories">Directories</a></li>
<li><a href="#files-and-directories-cheat-sheet">Files and Directories Cheat-Sheet</a></li>
</ul>
</li>
<li><a href="#reading-and-writing-csv-files">Reading and Writing CSV Files</a>
<ul>
<li><a href="#what-is-a-csv-file">What is a CSV file?</a></li>
<li><a href="#reading-csv-files">Reading CSV Files</a></li>
<li><a href="#generating-csv">Generating CSV</a></li>
<li><a href="#reading-and-writing-csv-files-with-dictionaries">Reading and Writing CSV Files with Dictionaries</a></li>
<li><a href="#csv-files-cheat-sheet">CSV Files Cheat Sheet</a></li>
</ul>
</li>
<li><a href="#regular-expressions">Regular Expressions</a>
<ul>
<li><a href="#introduction-to-regular-expressions">Introduction to Regular Expressions</a></li>
<li><a href="#what-are-regular-expressions">What are regular expressions?</a></li>
<li><a href="#why-use-regular-expressions">Why use regular expressions?</a></li>
<li><a href="#basic-matching-with-grep">Basic Matching with grep</a>
<ul>
<li><a href="#some-regex-reserved-characters">Some RegEx Reserved Characters</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#basic-regular-expressions">Basic Regular Expressions</a>
<ul>
<li><a href="#simple-matching-in-python">Simple Matching in Python</a></li>
<li><a href="#wildcards-and-character-classes">Wildcards and Character Classes</a></li>
<li><a href="#repetition-qualifiers">Repetition Qualifiers</a></li>
<li><a href="#escaping-characters">Escaping Characters</a></li>
<li><a href="#regular-expressions-in-action">Regular Expressions in Action</a></li>
<li><a href="#regular-expressions-cheat-sheet">Regular Expressions Cheat-Sheet</a></li>
</ul>
</li>
<li><a href="#advanced-regular-expressions">Advanced Regular Expressions</a>
<ul>
<li><a href="#capturing-groups">Capturing Groups</a></li>
<li><a href="#more-on-repetition-qualifiers">More on Repetition Qualifiers</a></li>
<li><a href="#extracting-a-pid-using-regexes-in-python">Extracting a PID Using regexes in Python</a></li>
<li><a href="#splitting-and-replacing">Splitting and Replacing</a></li>
<li><a href="#advanced-regular-expressions-cheat-sheet">Advanced Regular Expressions Cheat-Sheet</a></li>
</ul>
</li>
<li><a href="#managing-data-and-processes">Managing Data and Processes</a>
<ul>
<li><a href="#data-streams">Data Streams</a></li>
<li><a href="#reading-data-interactively">Reading Data interactively</a></li>
<li><a href="#standard-streams">Standard Streams</a></li>
<li><a href="#environment-variables">Environment Variables</a></li>
<li><a href="#command-line-arguments-and-exit-status">Command-Line Arguments and Exit Status</a></li>
</ul>
</li>
<li><a href="#python-subprocesses">Python Subprocesses</a>
<ul>
<li><a href="#running-system-commands-in-python">Running System Commands in Python</a></li>
<li><a href="#obtaining-the-output-of-a-system-command">Obtaining the Output of a System Command</a></li>
<li><a href="#advanced-subprocess-management">Advanced Subprocess Management</a></li>
<li><a href="#python-subprocesses-cheat-sheet">Python Subprocesses Cheat Sheet</a></li>
</ul>
</li>
<li><a href="#processing-log-files">Processing Log Files</a>
<ul>
<li><a href="#what-are-log-files">What are log files?</a></li>
<li><a href="#filtering-log-files-with-regular-expressions">Filtering Log Files with Regular Expressions</a></li>
<li><a href="#making-sense-out-of-the-data">Making Sense out of the Data</a></li>
</ul>
</li>
<li><a href="#testing-in-python">Testing in Python</a>
<ul>
<li><a href="#simple-tests">Simple Tests</a></li>
<li><a href="#what-is-testing">What is testing?</a></li>
<li><a href="#manual-testing-and-automated-testing">Manual Testing and Automated Testing</a></li>
</ul>
</li>
<li><a href="#unit-tests">Unit Tests</a>
<ul>
<li><a href="#writing-unit-tests-in-python">Writing Unit Tests in Python</a></li>
<li><a href="#edge-cases">Edge Cases</a></li>
<li><a href="#additional-test-cases">Additional Test Cases</a></li>
</ul>
</li>
<li><a href="#other-tests-concepts">Other Tests Concepts</a>
<ul>
<li><a href="#black-box-vs.-white-box">Black Box vs. White Box</a></li>
<li><a href="#other-test-types">Other Test Types</a></li>
<li><a href="#test-driven-development">Test-Driven Development</a></li>
<li><a href="#more-about-tests">More About Tests</a></li>
</ul>
</li>
<li><a href="#errors-and-exceptions">Errors and Exceptions</a>
<ul>
<li><a href="#the-try-except-construct">The Try-Except Construct</a></li>
<li><a href="#raising-errors">Raising Errors</a></li>
<li><a href="#testing-for-expected-errors">Testing for Expected Errors</a></li>
</ul>
</li>
<li><a href="#bash-scripting">Bash Scripting</a>
<ul>
<li><a href="#basic-linux-commands">Basic Linux Commands</a></li>
<li><a href="#redirecting-streams">Redirecting Streams</a></li>
<li><a href="#pipes-and-pipelines">Pipes and Pipelines</a></li>
<li><a href="#signalling-processes">Signalling Processes</a></li>
</ul>
</li>
<li><a href="#scripting-with-bash">Scripting with Bash</a>
<ul>
<li><a href="#creating-bash-scripts">Creating Bash Scripts</a></li>
<li><a href="#using-variables-and-globs">Using Variables and Globs</a></li>
<li><a href="#conditional-execution-in-bash">Conditional Execution in Bash</a></li>
<li><a href="#bash-scripting-resources">Bash Scripting Resources</a></li>
</ul>
</li>
<li><a href="#advanced-bash-concepts">Advanced Bash Concepts</a>
<ul>
<li><a href="#while-loops-in-bash-scripts">While Loops in Bash Scripts</a></li>
<li><a href="#for-loops-in-bash-scripts">For Loops in Bash Scripts</a></li>
<li><a href="#advanced-command-interaction">Advanced Command Interaction</a></li>
<li><a href="#choosing-between-bash-and-python">Choosing Between Bash and Python</a></li>
</ul>
</li>
<li><a href="#final-project">Final Project</a>
<ul>
<li><a href="#writing-a-script-from-the-ground-up">Writing a Script from the Ground Up</a></li>
<li><a href="#problem-statement-2">Problem Statement #2</a></li>
<li><a href="#help-with-research-and-planning">Help with Research and Planning</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
  </div>
  <div class="stackedit__right">
    <div class="stackedit__html">
      <h1 id="using-python-to-interact-with-the-operating-system">2. Using Python to Interact with the Operating System</h1>
<h2 id="course-introduction">Course Introduction</h2>
<h3 id="finding-out-more-information">Finding out more information</h3>
<p>Throughout this course, we teach you how to do a range of things with Python, Bash, and other tools. While we’ll provide a lot of information through videos and supplemental readings, sometimes, you may need to look things up on your own, now and throughout your career. Things change fast in IT, so it’s critical to do your own research to stay up-to-date on what’s new. We recommend you use your favorite search engine to find more information about concepts we cover in this course — it’s great practice for the real world!</p>
<p>On top of search results, here are some good programming resources available online:</p>
<ul>
<li>
<p><a href="https://automatetheboringstuff.com/">Automate the Boring Stuff with Python</a>: This book (available online and in print) includes a lot of practical programming exercises for beginners. You can refer to this content to read more about some of the things that we’ll be discussing, and get inspired with more ideas of things that can be automated.</p>
</li>
<li>
<p><a href="https://docs.python-guide.org/">Hitchhiker’s Guide to Python</a>: This site (available online and in print) also covers a lot of what we can do with Python. Again, you can use this resource to learn more about the subjects we cover (and the ones we had to omit for time constraints).</p>
</li>
<li>
<p>The <a href="https://docs.python.org/3/reference/index.html">official language reference</a>: Once you know what Python tool you’ll be using to do a certain task, this technical reference of all Python language components can be a great [missing from website]</p>
</li>
</ul>
<h3 id="getting-familiar-with-the-operating-system">Getting Familiar with the Operating System</h3>
<p>The operating system is a software that manages everything that goes on in the computer.</p>
<p>It reads, writes, and deletes files from the hard drive. It handles how the processes start, how they interact with each other, and how they eventually finish.<br>
It manages how memory gets allocated different processes, how network packets are sent and received, and how each programming can access the different hardware components.</p>
<p>Since it’s cross-platform, we can use the same Python code to get to our goal on any operating system, whether the goal is opening files, processing text, or managing running processes. This makes Python a great tool for IT specialists who needs to interact with different operating systems. You can apply the skills that you learned from one platform to all the others. So how cool is that?</p>
<h3 id="getting-your-computer-ready-for-python">Getting Your Computer Ready for Python</h3>
<p>Some modules of interest from the Python Standard Library, to import in our scripts with the <strong>import</strong> keyword:</p>
<ul>
<li>requests and request.get() to work with web pages</li>
<li>arrow and arrow.get() to work with dates</li>
<li>the Image submodule from the Python Image Library: image.open(), image.size() and image.format()</li>
<li>pandas for data science: pandas.DataFrame({…})</li>
</ul>
<h3 id="pointers-for-getting-your-environment-setup">Pointers for Getting Your Environment Setup</h3>
<h4 id="learning-more-about-operating-systems">Learning more about operating systems</h4>
<p>We’ve talked briefly about what an operating system is and what we’ll need to know about operating systems for this course. If you want to learn some additional operating system concepts, check out the videos on this subject in the <a href="https://www.coursera.org/lecture/technical-support-fundamentals/module-introduction-I3n9l">Technical Support Fundamentals course</a>. If you want to dive deeper onto how to manage Windows and Linux, check out the <a href="https://www.coursera.org/learn/os-power-user">Operating Systems and You: Becoming a Power User course</a>.</p>
<p>If you want to discover more about the history of Unix, you can read all the details on the <a href="https://en.wikipedia.org/wiki/History_of_Unix">Unix Wikipedia page</a>.</p>
<h4 id="installing-python-and-additional-modules">Installing Python and additional modules</h4>
<p>If you don’t have Python installed yet, we recommend that you visit the <a href="http://www.python.org/">official Python website</a> and download the installer that corresponds to your operating system.</p>
<p>There’s a bunch of guides out there for installing Python and they all follow a similar process to the one we described in the videos. This <a href="https://realpython.com/installing-python/">guide from Real Python</a> includes instructions on how to install python on a range of different operating systems and distributions.</p>
<p>Once you have Python installed on your operating system, it’s a good idea to familiarize yourself with <strong>pip and the associated tools</strong>. You can find more info about these <a href="https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/">here</a>.</p>
<h4 id="using-package-management-systems">Using package management systems</h4>
<p>Package management systems help you better manage the software installed on your machine. These management systems vary a lot from operating system to operating system. So, you need to pick the one that works for the OS you’re using. Check out these guides for help with this:</p>
<ul>
<li>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-windows-10">Installing Python 3 on Windows 10 with Chocolatey</a></p>
</li>
<li>
<p><a href="http://www.pyladies.com/blog/Get-Your-Mac-Ready-for-Python-Programming/">Installing Python 3 on MacOS with Homebrew</a></p>
</li>
<li>
<p><a href="https://www.digitalocean.com/community/tutorials/package-management-basics-apt-yum-dnf-pkg">Package management basics on Linux</a></p>
</li>
</ul>
<h4 id="other-information">Other information</h4>
<ul>
<li><a href="https://devblogs.microsoft.com/python/python-in-the-windows-10-may-2019-update/">Python in the Microsoft Store for Windows 10</a></li>
</ul>
<h3 id="running-python-locally">Running Python Locally</h3>
<h4 id="interpreted-vs.-compiled-languages">Interpreted vs. Compiled Languages</h4>
<h4 id="how-to-run-a-python-script">How to Run a Python Script</h4>
<p>Notion of “shebang”: for Python scripts file, include #!/bin/env python3 in the first line and then make the file executable by using the command chmod +x<br>
Finally, remember to prefix the file name with ./, to let the command line interpreter know that it should find the script in the current directory.</p>
<h4 id="setting-up-your-environment">Setting up Your Environment</h4>
<p>After you’ve installed Python and checked that it works, the next step to set up your developer environment is to choose your main code editor.</p>
<p>These are some of the common editors for Python, available for all platforms:</p>
<ul>
<li>
<p><a href="http://www.eclipse.org/">Eclipse</a></p>
</li>
<li>
<p><a href="https://www.jetbrains.com/pycharm/">PyCharm</a></p>
</li>
<li>
<p><a href="http://www.sublimetext.com/">Sublime Text</a></p>
</li>
<li>
<p><a href="https://vscodium.com/">VSCodium</a></p>
</li>
</ul>
<p>You can read more about these editors, and others, in these overview comparatives:</p>
<ul>
<li>
<p><a href="https://realpython.com/python-ides-code-editors-guide/#pycharm">Python IDEs and Code Editors (Guide)</a></p>
</li>
<li>
<p><a href="https://www.softwaretestinghelp.com/python-ide-code-editors/">Best Python IDEs and Code Editors</a></p>
</li>
<li>
<p><a href="https://www.datacamp.com/community/tutorials/data-science-python-ide">Top 5 Python IDEs for Data Science</a></p>
</li>
</ul>
<p>We encourage you to try out these editors and pick your favorite. Then, install it on your computer and experiment with writing and executing Python scripts locally.</p>
<h2 id="automating-tasks-through-programming">Automating Tasks Through Programming</h2>
<h3 id="benefits-of-automation">Benefits of Automation</h3>
<p>Scability: when more work is added to a system, the system can do whatever it needs to complete the work.</p>
<h3 id="pitfalls-of-automation">Pitfalls of Automation</h3>
<h4 id="is-it-worth-the-time">Is it worth the time?</h4>
<p>Is the time and effort it’ll take to write the script worth the potential automation benefits?</p>
<p>A simple heuristic that can help us decide is to estimate how long it takes us to do a certain task. And then multiply that by how many times we perform that task in a given time window. If we estimate that it would take less time to automate the tasks than it would to do it manually, chances are, it’s a good candidate for automation. So, the time to write the automation is less than time to perform the task multiply by the amount of times you do it, then automate the task.</p>
<p><code>time_to_automate &lt; (time_to_perform * amount_of_times_done)</code></p>
<p><img src="Images/is_it_worth_the_time.png" alt="Is it worth the time?"><br>
Source: <a href="https://xkcd.com/1205">xkcd</a></p>
<p>Usually, the decision of whether to automate or not isn’t so straightforward. If a task is complex and performed in frequently, it may seem like automating is more trouble than it’s worth.</p>
<p>But keep in mind that once a task is wrapped in automation, anyone can do it. It can be very useful to automate a complex error prone task. If it’s critical that the tasks be done correctly, even if it’s not executed that often.</p>
<p>There are no hard and fast rules on when to automate, but the cost time tradeoff can help guide your decisions.</p>
<p>A concept called the Pareto Principle can also be a useful guideline to help you decide which tasks to automate. When applied to automation in IT, the Pareto Principle states that 20% of the system administration tasks that you perform are responsible for 80% of your work. If you can identify and automate those 20% of your tasks, you could save yourself a whole lot of time.</p>
<h3 id="practical-automation-example">Practical Automation Example</h3>
<p>Computer “health”: a few modules can help designing a script to check the “health” of a computer system (disk usage, cpu load, etc.): the <em><strong>shutil</strong></em> and <em><strong>psutil</strong></em> ones.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> shutil
du <span class="token operator">=</span> shutil<span class="token punctuation">.</span>disk_usage<span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span> <span class="token comment">#directory to check</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>du<span class="token punctuation">)</span>
du<span class="token punctuation">.</span>free<span class="token operator">/</span>du<span class="token punctuation">.</span>total<span class="token operator">*</span><span class="token number">100</span>
</code></pre>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> psutil
psutil<span class="token punctuation">.</span>cpu_percent<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span> <span class="token comment"># interval of time to check the cpu load in\</span>
 seconds<span class="token punctuation">,</span> returns the average usage over said period
</code></pre>
<p>Now that we’ve done some research, let’s write a first basic health checking script:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>
<span class="token keyword">import</span> shutil
<span class="token keyword">import</span> psutil

<span class="token keyword">def</span> <span class="token function">check_disk_usage</span><span class="token punctuation">(</span>disk<span class="token punctuation">)</span><span class="token punctuation">:</span>
  du <span class="token operator">=</span> shutil<span class="token punctuation">.</span>disk_usage<span class="token punctuation">(</span>disk<span class="token punctuation">)</span>
  free <span class="token operator">=</span> du<span class="token punctuation">.</span>free <span class="token operator">/</span> du<span class="token punctuation">.</span>total <span class="token operator">*</span> <span class="token number">100</span>
  <span class="token keyword">return</span> free <span class="token operator">&gt;</span> <span class="token number">20</span>

<span class="token keyword">def</span> <span class="token function">check_cpu_usage</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  usage <span class="token operator">=</span> psutil<span class="token punctuation">.</span>cpu_percent<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span>  usage <span class="token operator">&lt;</span> <span class="token number">70</span>

<span class="token triple-quoted-string string">"""Main body of script that checks if the 2 conditions described in\
 the 2 functions are false
"""</span>
<span class="token keyword">if</span> <span class="token operator">not</span> check_disk_usage<span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token operator">not</span> check_cpu_usage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Error!"</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Everything is OK!"</span><span class="token punctuation">)</span>
</code></pre>
<p>Remember to mark the script as executable and to test it. We’ll improve on it later.</p>
<h2 id="reading-and-writing-files">Reading and Writing Files</h2>
<h3 id="programming-with-files">Programming with Files</h3>
<p>Notions of directory/folder and file, filesystem hierarchy/tree. Notions of absolute vs relative PATH.</p>
<h3 id="reading-files">Reading Files</h3>
<pre class=" language-python"><code class="prism  language-python"><span class="token builtin">file</span> <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"spider.txt"</span><span class="token punctuation">)</span>
</code></pre>
<p>When we open a file, like we’re doing in this example, the operating system checks<br>
that we have permissions to access that file and then gives our code a <strong>File descriptor</strong>: this is a token generated by the OS that allows programs to do more operations with the file.</p>
<p>In Python, this file descriptor is stored as an attribute of the files object.<br>
The file object gives us a bunch of methods that we can use to operate with the file.</p>
<p>Now, with this file object, we can read the contents of the file and print them to the screen.</p>
<h4 id="the-open-use-close-approach">The “Open-Use-Close” Approach</h4>
<pre class=" language-python"><code class="prism  language-python"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token builtin">file</span> <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"spider.txt"</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token builtin">file</span><span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>
The itsy bitsy spider climbed up the waterspout<span class="token punctuation">.</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token builtin">file</span><span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>
Down came the rain
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token builtin">file</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">and</span> washed the spider out<span class="token punctuation">.</span>
Out came the sun
<span class="token operator">and</span> dried up <span class="token builtin">all</span> the rain
<span class="token operator">and</span> the itty bitsy spider climbed up the spout again<span class="token punctuation">.</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token builtin">file</span><span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Handy if we intend to work with the file several times in our code. Remember to close the file! It’s best pratice to:</p>
<ul>
<li>Allow other programs to work with the file otherwise locked</li>
<li>Prevent the OS from running out of file descriptors (even if that number is generally high)</li>
<li>Prevent race conditions. “Everybody looses in a race condition.”</li>
</ul>
<h4 id="the-with-approach">The “With” Approach</h4>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"spider.txt"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
  <span class="token builtin">file</span><span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Using this approach, Python automatically closes the opened file(s). Handy if we intend to work with the file only once in our code.</p>
<h3 id="iterating-through-files">Iterating through Files</h3>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"spider.txt"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

THE ITSY BITSY SPIDER CLIMBED UP THE WATERSPOUT<span class="token punctuation">.</span>

DOWN CAME THE RAIN

AND WASHED THE SPIDER OUT<span class="token punctuation">.</span>

OUT CAME THE SUN

AND DRIED UP ALL THE RAIN

AND THE ITTY BITSY SPIDER CLIMBED UP THE SPOUT AGAIN<span class="token punctuation">.</span>
</code></pre>
<p>The text contains the new line invisible character \n. Notion of <strong>escaping sequences</strong>: \t for tabs.</p>
<p>To remove the new line the print() command actually outputs for each line:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"spider.txt"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
THE ITSY BITSY SPIDER CLIMBED UP THE WATERSPOUT<span class="token punctuation">.</span>
DOWN CAME THE RAIN
AND WASHED THE SPIDER OUT<span class="token punctuation">.</span>
OUT CAME THE SUN
AND DRIED UP ALL THE RAIN
AND THE ITTY BITSY SPIDER CLIMBED UP THE SPOUT AGAIN<span class="token punctuation">.</span>
</code></pre>
<p>The <em><strong>readlines()</strong></em> method (≠ .readline())</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token builtin">file</span> <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"spider.txt"</span><span class="token punctuation">)</span>
lines <span class="token operator">=</span> <span class="token builtin">file</span><span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token builtin">file</span><span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># Even though the file object is now closed, the lines\</span>
 variable has the <span class="token builtin">list</span> of lines <span class="token keyword">in</span> the <span class="token builtin">file</span><span class="token punctuation">,</span> so we can operate on it<span class="token punctuation">.</span>
</code></pre>
<p>A quick word of <strong>caution</strong>, methods like <em><strong>read</strong></em> or <em><strong>readlines</strong></em> that read the whole file at once are useful, but we should be careful when reading the entire contents of a file into a variable of our programs.</p>
<p>If the file is super large, it can take a lot of our computer’s memory to hold it,<br>
which can lead to poor performance.</p>
<p>If a file is just a few kilobytes like in our example here, it’s fine to read it and process it completely in memory.</p>
<p>But for large files, like the big log file of hundreds and hundreds of megabytes of data, it’s more efficient to process it line by line.</p>
<h3 id="writing-files">Writing Files</h3>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"novel.txt"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
  <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"It was a dark and stormy night"</span><span class="token punctuation">)</span>

<span class="token number">30</span>
</code></pre>
<h4 id="notion-of-file-modes-see-cheat-sheet-below">Notion of file modes (see Cheat-Sheet below)</h4>

<table>
<thead>
<tr>
<th>Mode</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>r</td>
<td>read-only (default, not mandatory)</td>
</tr>
<tr>
<td>w</td>
<td>write-only (overwrites existing content, creates the file if it doesn’t exists)</td>
</tr>
<tr>
<td>a</td>
<td>Append at the end of the file</td>
</tr>
<tr>
<td>r+</td>
<td>Read-Write</td>
</tr>
</tbody>
</table><p>Another word of <strong>caution</strong>: If you open a file for <strong>writing and the file already exists, the old contents will be deleted as soon as the file is opened</strong>.</p>
<p>Remember to double check that you’re opening the right file using the right mode.</p>
<h3 id="reading-and-writing-files-cheat-sheet">Reading and Writing Files Cheat-Sheet</h3>
<p>Check out the following link for more information:</p>
<p><a href="https://docs.python.org/3/library/functions.html#open">https://docs.python.org/3/library/functions.html#open</a></p>
<h2 id="managing-files-and-directories">Managing Files and Directories</h2>
<h3 id="working-with-files">Working with Files</h3>
<p>Let’s explore some of the many things that we can do with files in Python with the <em><strong>os</strong></em> module.</p>
<p><strong>Caution</strong>: Paths can be different across different operating systems. So whenever we’re using an absolute path in our code, we need to make sure we can provide alternatives for the platforms we want to support.</p>
<p>The OS module lets us do pretty much all the same tasks that we can normally<br>
do when working with files from the command line. We can change the file permissions and delete or rename files through our code. This means you can write scripts to do these operations for you automatically.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> os
os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span><span class="token string">"novel.txt"</span><span class="token punctuation">)</span> <span class="token comment"># To delete a file</span>

os<span class="token punctuation">.</span>rename<span class="token punctuation">(</span><span class="token string">"old_file_name"</span><span class="token punctuation">,</span> <span class="token string">"new_file_name"</span><span class="token punctuation">)</span> <span class="token comment"># To rename a file</span>

os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token string">"some_file_name"</span><span class="token punctuation">)</span> <span class="token comment"># Returns either True or False,\</span>
 depending on the presence of the <span class="token builtin">file</span>
</code></pre>
<h3 id="more-file-information">More File Information</h3>
<pre class=" language-python"><code class="prism  language-python">os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>getsize<span class="token punctuation">(</span><span class="token string">"spider.txt"</span><span class="token punctuation">)</span> <span class="token comment"># Returns the file size in bytes</span>

os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>getmtime<span class="token punctuation">(</span><span class="token string">"spider.txt"</span><span class="token punctuation">)</span> <span class="token comment"># Returns the last modification time\</span>
 <span class="token operator">and</span> date of the <span class="token builtin">file</span>
</code></pre>
<p>Notion of <strong>Timestamp</strong>: a Unix timestamp for example represents the number of seconds since January 1st, 1970.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> datetime
timestamp <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>getmtime<span class="token punctuation">(</span><span class="token string">"spider.txt"</span><span class="token punctuation">)</span>
datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>fromtimestamp<span class="token punctuation">(</span>timestamp<span class="token punctuation">)</span>
</code></pre>
<pre class=" language-python"><code class="prism  language-python">os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span><span class="token string">"spider.txt"</span><span class="token punctuation">)</span>
`<span class="token operator">/</span>Volumes<span class="token operator">/</span>GoogleDrive<span class="token operator">/</span>Mon Drive<span class="token operator">/</span>Documents<span class="token operator">/</span>Cours<span class="token operator">/</span>Google IT Automation\
 <span class="token keyword">with</span> Python Professional Certificate<span class="token operator">/</span>spider<span class="token punctuation">.</span>txt'
</code></pre>
<h3 id="directories">Directories</h3>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># Prints the current working directory</span>

os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span><span class="token string">"New folder"</span><span class="token punctuation">)</span> <span class="token comment"># To create a new folder, aptly named\</span>
 New folder
os<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span><span class="token string">"New folder"</span><span class="token punctuation">)</span> <span class="token comment"># To enter this newly created folder</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># Outputs [...]/New folder</span>

os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span><span class="token string">"Newer folder"</span><span class="token punctuation">)</span>
os<span class="token punctuation">.</span>rmdir<span class="token punctuation">(</span><span class="token string">"Newer folder"</span><span class="token punctuation">)</span> <span class="token comment"># Will only delete the folder if it's empty</span>
</code></pre>
<p>The <strong>rmdir</strong> function will only work if the directory is empty. If we try to remove a directory that has files in it, we get an error. We need to first delete all the files and sub-directories in that directory before we can actually remove it but how can we find out what contents are in that directory?</p>
<p>There are a few techniques that we can use to do this. The <strong>os.listdir</strong> function returns a list of all the files and sub-directories in a given directory.<br>
Let’s see how this looks for our website directory.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> os
os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span><span class="token string">"website"</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'images'</span><span class="token punctuation">,</span> <span class="token string">'index.html'</span><span class="token punctuation">,</span> <span class="token string">'favicon.ico'</span><span class="token punctuation">]</span>
</code></pre>
<p>So we’ve got a list of strings. Since they’re just strings, we don’t know if they’re directories or files. To find out what they are, we can use functions like<br>
<strong>os.path.isdir</strong> but before we look at how that works. See how the list contains just file names. If we want to know whether one of these files is a directory, we need to use <strong>os.path.join</strong> to create the full path. Let’s see all of this in action now.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token builtin">dir</span> <span class="token operator">=</span> <span class="token string">"website"</span>

<span class="token keyword">for</span> name <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span><span class="token builtin">dir</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
     fullname <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token builtin">dir</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>
     <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span>fullname<span class="token punctuation">)</span><span class="token punctuation">:</span>
         <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{} is a directory"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>fullname<span class="token punctuation">)</span><span class="token punctuation">)</span>
     <span class="token keyword">else</span><span class="token punctuation">:</span>
         <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{} is a file"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>fullname<span class="token punctuation">)</span><span class="token punctuation">)</span>

website<span class="token operator">/</span>images <span class="token keyword">is</span> a directory
website<span class="token operator">/</span>index<span class="token punctuation">.</span>html <span class="token keyword">is</span> a <span class="token builtin">file</span>
website<span class="token operator">/</span>favicon<span class="token punctuation">.</span>ico <span class="token keyword">is</span> a <span class="token builtin">file</span>
</code></pre>
<p>What’s up with that join function? It seems to just add a slash between two strings. Well, the join function let’s us be independent from the operating system again.</p>
<ul>
<li>
<p>In <strong>Linux and MacOS</strong>, the portions of a file are split using a <strong>forward slash</strong>.</p>
</li>
<li>
<p>On <strong>Windows</strong>, they’re split using a <strong>backslash</strong>.</p>
</li>
</ul>
<p>By using the os.path.join function instead of explicitly adding a slash, we can make sure that our scripts -<br>
work with all operating systems.</p>
<h3 id="files-and-directories-cheat-sheet">Files and Directories Cheat-Sheet</h3>
<p>Check out the following links for more information:</p>
<ul>
<li>
<p><a href="https://docs.python.org/3/library/os.html">os — Miscellaneous operating system interfaces</a></p>
</li>
<li>
<p><a href="https://docs.python.org/3/library/os.path.html">os.path — Common pathname manipulations</a></p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Unix_time">Unix time Wikipedia page</a></p>
</li>
</ul>
<h2 id="reading-and-writing-csv-files">Reading and Writing CSV Files</h2>
<h3 id="what-is-a-csv-file">What is a CSV file?</h3>
<p>Notion of parsing a file: Analyzing a file’s content to correctly structure the data.</p>
<p>CSV stands for Comma Separated Values. It’s one of the many file formats used to structure data, like HTML or JSON.</p>
<p>A lot of programs are capable of exporting data as CSV files, such as spreadsheet applications like Microsoft Excel or Google Sheets. It can actually be helpful to think of a CSV file like it’s a spreadsheet, where each line corresponds to a row and each comma separated field corresponds to a column.</p>
<h3 id="reading-csv-files">Reading CSV Files</h3>
<p>Python standard library includes a module which lets us read, create and manipulate CSV files: the <strong>csv</strong> module.</p>
<p>Before we can parse a CSV file, we need to open the file the same way as before. We can then parse this file using the CSV module.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> csv
f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"csv_file.csv"</span><span class="token punctuation">)</span>
csv_f <span class="token operator">=</span> csv<span class="token punctuation">.</span>reader<span class="token punctuation">(</span>f<span class="token punctuation">)</span> <span class="token comment"># We now have an instance of the CSV reader\</span>
 <span class="token keyword">class</span>
<span class="token class-name">for</span> row <span class="token keyword">in</span> csv_f<span class="token punctuation">:</span>
  name<span class="token punctuation">,</span> twitter_handle<span class="token punctuation">,</span> nickname <span class="token operator">=</span> row <span class="token comment"># See notion of unpacking</span>
  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Name: {}, Twitter handle: {}, Nickname: {}."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>\
   twitter_handle<span class="token punctuation">,</span> nickname<span class="token punctuation">)</span><span class="token punctuation">)</span>
f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># Remember to close the file when using the "Open-Use-\</span>
Approach"
</code></pre>
<p><strong>Notion of unpacking</strong>: the row variable hold each row in the CSV file.<br>
This variable is a list with each field in the CSV corresponding to one<br>
element in the list. We know from the before that the first field is a name, the second one, the Twitter handle, and the third, the nickname. So we can <strong>unpack</strong> the values so that we can use variables to refer to them. <strong>Remember</strong> that for this to work we need to have the exact same amount of variables on the left side of the equal sign as the length of the sequence on the right side.</p>
<p>We could have used row[0] to access the name of the employee. This is valid but it can be hard to follow when reading a lot of code. Unpacking the list into name variables makes the code easier to understand later on.</p>
<h3 id="generating-csv">Generating CSV</h3>
<p>we can use the writer function to generate contents to a file. This can be really helpful if you process some data in your script and you must store it in a file.<br>
Maybe you want to import it into a spreadsheet or use it later on in your script.<br>
We’ll start by storing the data that we want to write into a list.</p>
<p>There are two functions that we can use: <em><strong>writerow</strong></em>, which we’ll write one row at a time; and <em><strong>writerows</strong></em>, which we’ll write all of them together. In this case, we already have all the data that we want to write. So we’ll call writerows.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> csv
hosts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">"MacBook-Air.local"</span><span class="token punctuation">,</span> <span class="token string">"192.168.1.43"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">"fedora.local"</span><span class="token punctuation">,</span>\
 <span class="token string">"192.168.1.73"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">"fedorapi.local"</span><span class="token punctuation">,</span> <span class="token string">"192.168.1.80"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"hosts.csv"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> hosts_csv<span class="token punctuation">:</span>
  writer <span class="token operator">=</span> csv<span class="token punctuation">.</span>writer<span class="token punctuation">(</span>hosts_csv<span class="token punctuation">)</span> <span class="token comment"># the writer variable is now an\</span>
   instance of the csv writer <span class="token keyword">class</span>
  <span class="token class-name">writer</span><span class="token punctuation">.</span>writerows<span class="token punctuation">(</span>hosts<span class="token punctuation">)</span>
</code></pre>
<h3 id="reading-and-writing-csv-files-with-dictionaries">Reading and Writing CSV Files with Dictionaries</h3>
<p>We saw how we can read and write CSV files, and we use list as datatype on the Python side. This works when we know what the fields are going to be, but it can be pretty cumbersome when we have a lot of columns, and we need to remember which is which. Imagine if your lists of employees not only had name, phone number and role but also start date, username, office location, department, preferred pronouns and so on. It would soon get hard to keep track of which column corresponds to which position in the row. For cases like this, it’s common for CSVs to include the names of the columns as a first line in the file.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> csv
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"software.csv"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> software<span class="token punctuation">:</span>
  reader <span class="token operator">=</span> csv<span class="token punctuation">.</span>DictReader<span class="token punctuation">(</span>software<span class="token punctuation">)</span>
  <span class="token keyword">for</span> row <span class="token keyword">in</span> reader<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"{} has {} users."</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">,</span> row<span class="token punctuation">[</span><span class="token string">"users"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<pre class=" language-python"><code class="prism  language-python">users <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"Sol Mansi"</span><span class="token punctuation">,</span> <span class="token string">"username"</span><span class="token punctuation">:</span> <span class="token string">"solm"</span><span class="token punctuation">,</span> <span class="token string">"department"</span><span class="token punctuation">:</span>\
 <span class="token string">"IT\  Infrastructure"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"Lio Nelson"</span><span class="token punctuation">,</span> <span class="token string">"username"</span><span class="token punctuation">:</span> <span class="token string">"lion"</span><span class="token punctuation">,</span>\
 <span class="token string">"department"</span><span class="token punctuation">:</span> <span class="token string">"User Experience Research"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"Charlie Grey"</span><span class="token punctuation">,</span>\
   <span class="token string">"username"</span><span class="token punctuation">:</span> <span class="token string">"greyc"</span><span class="token punctuation">,</span> <span class="token string">"department"</span><span class="token punctuation">:</span> <span class="token string">"Development"</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
keys <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">,</span> <span class="token string">"username"</span><span class="token punctuation">,</span> <span class="token string">"departement"</span><span class="token punctuation">]</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'by_department.csv'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> by_department<span class="token punctuation">:</span>
  writer <span class="token operator">=</span> csv<span class="token punctuation">.</span>DictWriter<span class="token punctuation">(</span>by_department<span class="token punctuation">,</span> fieldnames<span class="token operator">=</span>keys<span class="token punctuation">)</span>
  writer<span class="token punctuation">.</span>writeheader<span class="token punctuation">(</span><span class="token punctuation">)</span>
  writer<span class="token punctuation">.</span>writerows<span class="token punctuation">(</span>users<span class="token punctuation">)</span>
</code></pre>
<p><em><strong>DictReader()</strong></em> allows us to convert the data in a CSV file into a standard dictionary. <em><strong>DictWriter()</strong></em> allows us to write data from a dictionary into a CSV file. The fieldnames parameter of DictWriter() requires a list of keys.</p>
<h3 id="csv-files-cheat-sheet">CSV Files Cheat Sheet</h3>
<p>Check out the following links for more information:</p>
<ul>
<li>
<p><a href="https://docs.python.org/3/library/csv.html">csv — CSV File Reading and Writing</a></p>
</li>
<li>
<p><a href="https://realpython.com/python-csv/">Reading and Writing CSV Files in Python</a></p>
</li>
</ul>
<h2 id="regular-expressions">Regular Expressions</h2>
<h3 id="introduction-to-regular-expressions">Introduction to Regular Expressions</h3>
<h3 id="what-are-regular-expressions">What are regular expressions?</h3>
<p>Regular expressions let you answer the questions like “what are all the four-letter words in a file?”, or “how many different error types are there in this error log?”.</p>
<p><strong>Regular expressions</strong> allow us to search a text for strings matching a specific pattern.</p>
<h3 id="why-use-regular-expressions">Why use regular expressions?</h3>
<p>At this point, you might be wondering why do I need more processing power than just looking for strings in a text which I already know how to do in Python? The answer lies in the power and flexibility of regular expressions.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
log <span class="token operator">=</span> "July <span class="token number">31</span> <span class="token number">07</span><span class="token punctuation">:</span><span class="token number">51</span><span class="token punctuation">:</span><span class="token number">48</span> mycomputer bad_process <span class="token punctuation">[</span><span class="token number">54321</span><span class="token punctuation">]</span><span class="token punctuation">:</span>\
 ERROR Performing package upgrade"
regex <span class="token operator">=</span> r<span class="token string">"\[(\d+)\]"</span>
result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>regex<span class="token punctuation">,</span> log<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="basic-matching-with-grep">Basic Matching with grep</h3>
<p>In our last example, we used a pretty complex regular expression from a Python program to look for a process ID. This is just one example of something we might want to do when processing texts from our Python scripts. We can also use regular expressions with a bunch of command line tools. <strong>Grep</strong> is an especially easy to use yet extremely powerful tool for applying regexes. It’s a great way to easily try out some expressions and get familiar with them. So let’s look at some basic matching we can do with grep.</p>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token function">grep</span> thon /usr/share/dict/words
</code></pre>
<p>When we call grep with thon as a pattern to match on and we pass our list of words as a file, we see that it matches with a bunch of different words.</p>
<p>It’s worth calling out that the string we’re passing in grep is case sensitive. So it needs to be matched exactly. If we use uppercase letters, they’ll only be matched by uppercase letters. If we wanted to match a string regardless of case, we will have to pass the -i parameter to the grep command, like this:</p>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token function">grep</span> -i python /usr/share/dict/words
</code></pre>
<p>We now know that any basic string is already a regular expression which will match a line that contains that string. To get the most out of regular expressions, we need to learn more of their syntax, which can be as complicated as it is powerful. In particular, we have to know the <strong>reserved characters</strong> that give extra meaning to the patterns that we create. It’s these characters that allow us to do more advanced matching than just checking for a literal string. For example, a dot matches any character. This means that if we include a dot in our expression, that dot is a wildcard that can be replaced by any other character in the results:</p>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token function">grep</span> l.rts /usr/share/dict/words
</code></pre>
<h4 id="some-regex-reserved-characters">Some RegEx Reserved Characters</h4>

<table>
<thead>
<tr>
<th>Reserved Character</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>.</td>
<td>“wildcard”, replaces any character</td>
</tr>
<tr>
<td>^ “anchor character”</td>
<td>Search for specified pattern at the beginning</td>
</tr>
<tr>
<td>$ “anchor character”</td>
<td>Search for specified pattern at the end</td>
</tr>
</tbody>
</table><pre class=" language-bash"><code class="prism  language-bash"><span class="token function">grep</span> ^fruit /usr/share/dict/words

<span class="token function">grep</span> cat$ /usr/share/dict/words
</code></pre>
<h2 id="basic-regular-expressions">Basic Regular Expressions</h2>
<h3 id="simple-matching-in-python">Simple Matching in Python</h3>
<p>As we called it out before, we use the <strong>re</strong> module to apply regular expressions in Python. This module includes a bunch of different functions that can help manipulate strings. Let’s see how we can use this module for some basic matching.</p>
<p>It’s a good idea/practive to always use <strong>rawstrings</strong> for regular expressions in Python.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"aza"</span><span class="token punctuation">,</span> <span class="token string">"plaza"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""Outputs: &lt;re.Match object; span=(2, 5), match='aza'&gt;"""</span>
result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"aza"</span><span class="token punctuation">,</span> <span class="token string">"bazaar"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""Outputs: &lt;re.Match object; span=(1, 4), match='aza'&gt;"""</span>
result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"aza"</span><span class="token punctuation">,</span> <span class="token string">"maze"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""Outputs: None"""</span>
</code></pre>
<p>When we’re applying regular expressions, we now know that if the search function returns None, it means it didn’t find a match. Let’s practice the special characters that we’ve seen up until now with a few examples.</p>
<pre class=" language-python"><code class="prism  language-python">result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"^x"</span><span class="token punctuation">,</span> <span class="token string">"xenon"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""Outputs: &lt;re.Match object; span=(0, 1), match='x'&gt;"""</span>
</code></pre>
<p>What happens when we use a dot?</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"p.ng"</span><span class="token punctuation">,</span> <span class="token string">"penguin"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'peng'</span><span class="token operator">&gt;</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"p.ng"</span><span class="token punctuation">,</span> <span class="token string">"clapping"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'ping'</span><span class="token operator">&gt;</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"p.ng"</span><span class="token punctuation">,</span> <span class="token string">"sponge"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'pong'</span><span class="token operator">&gt;</span>
</code></pre>
<h3 id="wildcards-and-character-classes">Wildcards and Character Classes</h3>
<p>. is the ultimate wildcard character, as it can replace any charater. What if we need to be stricter? Enter character classes.<br>
Character classes are encapsulated between square brackets.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"[Pp]ython"</span><span class="token punctuation">,</span> <span class="token string">"Python"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'Python'</span><span class="token operator">&gt;</span>
</code></pre>
<p>Notion of (regex) range: [a-z], [A-Z], [0-9]…</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"[a-z]way"</span><span class="token punctuation">,</span> <span class="token string">"The end of the highway"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'hway'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"[a-z]way"</span><span class="token punctuation">,</span> <span class="token string">"What a way to go!"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token boolean">None</span>
</code></pre>
<p>We can combine as many ranges and symbols as we want, like this:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"cloud[a-zA-Z0-9]"</span><span class="token punctuation">,</span> <span class="token string">"cloudy"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'cloudy'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"cloud[a-zA-Z0-9]"</span><span class="token punctuation">,</span> <span class="token string">"cloud9"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'cloud9'</span><span class="token operator">&gt;</span>
</code></pre>
<p>We can match anything that’s defined between the square brackets, which is useful. Sometimes we may want to match any characters that aren’t in a group.<br>
To do that, we use a circumflex inside the square brackets. For example, let’s create a search pattern that looks for any characters that’s not a letter:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"[^a-zA-Z]"</span><span class="token punctuation">,</span> <span class="token string">"This is a sentence with spaces."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\

<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">' '</span><span class="token operator">&gt;</span> <span class="token comment"># the span attribute \</span>
returns the position of the first space encountered
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"[^a-zA-Z ]"</span><span class="token punctuation">,</span> <span class="token string">"This is a sentence with spaces."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">31</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'.'</span><span class="token operator">&gt;</span>
</code></pre>
<p>If we want to match either one expression or another, we can use the pipe symbol to do that. This lets us list alternative options that can get matched. For example, we could have an expression that matches either the word cat or the word dog, like this:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"cat|dog"</span><span class="token punctuation">,</span> <span class="token string">"I like cats."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'cat'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"cat|dog"</span><span class="token punctuation">,</span> <span class="token string">"I like dogs."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'dogs'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"cat|dog"</span><span class="token punctuation">,</span> <span class="token string">"I like dogs and cats."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'dogs'</span><span class="token operator">&gt;</span>\
 <span class="token comment"># search only returns the first occurence</span>
</code></pre>
<p>If we want to get all possible matches, we can do that using the <strong>findall</strong> function, which is also provided by the <strong>re</strong> module, like this:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>r<span class="token string">"cat|dog"</span><span class="token punctuation">,</span> <span class="token string">"I like dogs and cats."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'dog'</span><span class="token punctuation">,</span> <span class="token string">'cat'</span><span class="token punctuation">]</span>
</code></pre>
<h3 id="repetition-qualifiers">Repetition Qualifiers</h3>
<p>It’s quite common to see expressions that include a dot followed by a star.<br>
This means that it matches any character repeated as many times as possible including zero.</p>
<p>Notion of <strong>repeated matches</strong>: .* and ?</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"Py.*n"</span><span class="token punctuation">,</span> <span class="token string">"Pygmalion"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'Pygmalion'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"Py.*n"</span><span class="token punctuation">,</span> <span class="token string">"Python programming"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'Python programmin'</span><span class="token operator">&gt;</span> <span class="token comment"># See note below</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"Py[a-z]*n"</span><span class="token punctuation">,</span> <span class="token string">"Python programming"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'Python'</span><span class="token operator">&gt;</span>
</code></pre>
<p>Remember, the Star takes as many characters as possible. In programming terms, we<br>
say that this behavior is <em><strong>greedy</strong></em>. It’s possible to modify the repetition qualifiers to make them less greedy.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
<span class="token keyword">def</span> <span class="token function">repeating_letter_a</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""The repeating_letter_a function checks if the text passed\
   includes the letter "a" (lowercase or uppercase) at least twice"""</span>
  result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"___"</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
  <span class="token keyword">return</span> result <span class="token operator">!=</span> <span class="token boolean">None</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>repeating_letter_a<span class="token punctuation">(</span><span class="token string">"banana"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># True</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>repeating_letter_a<span class="token punctuation">(</span><span class="token string">"pineapple"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># False</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>repeating_letter_a<span class="token punctuation">(</span><span class="token string">"Animal Kingdom"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># True</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>repeating_letter_a<span class="token punctuation">(</span><span class="token string">"A is for apple"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># True</span>
</code></pre>
<p>As we called out earlier, implementations of regular expressions aren’t always the same. Repetition qualifiers are one way they differ. Some implementations like the one used by grep only include the store qualifier that we just discussed. You can do a lot with just a star qualifier. So that’s usually good enough. Other implementations like the one used by Python or by the Egrep command include two additional repetition qualifiers plus and question mark, that can help us construct more complex expressions.</p>
<p>The + character matches one or more occurrences of the character that comes before it.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"o+l+"</span><span class="token punctuation">,</span> <span class="token string">"goldfish"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'ol'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"o+l+"</span><span class="token punctuation">,</span> <span class="token string">"woolly"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'ooll'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"o+l+"</span><span class="token punctuation">,</span> <span class="token string">"boil"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token boolean">None</span> <span class="token comment"># While there are both an o and a l, they're separated by a character.</span>
</code></pre>
<p>In this case, there was one occurrence of each. In the match pattern shows us the shortest possible matching string.</p>
<p>The question mark symbol is yet another multiplier. It means either zero or one occurrence of the character before it. Let’s see how this works:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"p?each"</span><span class="token punctuation">,</span> <span class="token string">"To each to their own"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># the ? renders the p optional</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'each'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"p?each"</span><span class="token punctuation">,</span> <span class="token string">"I like peaches!"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'peach'</span><span class="token operator">&gt;</span>
</code></pre>
<h3 id="escaping-characters">Escaping Characters</h3>
<p>We can use a <strong>backslash</strong> in this way to escape any special characters, including the ones that we haven’t even talked about yet.</p>
<p>Something to watch out for: it can get really confusing with backslashes since they’re also used to define some special string characters.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">".com"</span><span class="token punctuation">,</span> <span class="token string">"Welcome!"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'lcom'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"\.com"</span><span class="token punctuation">,</span> <span class="token string">"Welcome!"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token boolean">None</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">".com"</span><span class="token punctuation">,</span> <span class="token string">"mydomain.com"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'.com'</span><span class="token operator">&gt;</span>
</code></pre>
<p>We’ve called out, for example, that <strong>\n</strong> is a sequence using Python to indicate a new line, and <strong>\t</strong> does the same for tabs. <strong>When we see a pattern that includes a backslash, it could be escaping a special regex character or a special string character</strong>.</p>
<p>Using raw strings, like we’ve been doing, helps avoid some of these possible confusion because the special characters won’t be interpreted when generating the string. They will only be interpreted when parsing the regular expression.</p>
<p>On top of this, Python also uses the backslash for a few special sequences that we can use to represent predefined sets of characters. For example, <strong>\w</strong> matches any alphanumeric character including letters, numbers, and underscores.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"\w*"</span><span class="token punctuation">,</span> <span class="token string">"This is an example."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'This'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"\w*"</span><span class="token punctuation">,</span> <span class="token string">"And_this_is_another!"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'And_this_is_another'</span><span class="token operator">&gt;</span>
</code></pre>
<p>There’s also <strong>\d</strong> for matching digits, <strong>\s</strong> for matching whitespace characters like space, tab or new line, <strong>\b</strong> for word boundaries and a few others.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
<span class="token keyword">def</span> <span class="token function">check_character_groups</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Fill in the code to check if the text passed has at least 2 groups of alphanumeric characters (including letters, numbers, and underscores) separated by one or more whitespace characters."""</span>
  result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"____"</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
  <span class="token keyword">return</span> result <span class="token operator">!=</span> <span class="token boolean">None</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>check_character_groups<span class="token punctuation">(</span><span class="token string">"One"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># False</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>check_character_groups<span class="token punctuation">(</span><span class="token string">"123 Ready Set GO"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># True</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>check_character_groups<span class="token punctuation">(</span><span class="token string">"username user_01"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># True</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>check_character_groups<span class="token punctuation">(</span><span class="token string">"shopping_list: milk, bread, eggs."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="regular-expressions-in-action">Regular Expressions in Action</h3>
<p>We’ve now looked into a bunch of syntax for using regular expressions in Python. Armed with all this knowledge, we can start combining these special characters to create patterns to match the text that we want. For example, say you had a list of all the countries in the world and you want to check which of those names start and end in a. What will the pattern look like? Maybe something like this, A.*a. Let’s try that one out:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"A.*a"</span><span class="token punctuation">,</span> <span class="token string">"Argentina"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'Argentina'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"A.*a"</span><span class="token punctuation">,</span> <span class="token string">"Azerbaijan"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'Azerbaija'</span><span class="token operator">&gt;</span> <span class="token comment"># Not quite</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"^A.*a$"</span><span class="token punctuation">,</span> <span class="token string">"Azerbaijan"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token boolean">None</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"^A.*a$"</span><span class="token punctuation">,</span> <span class="token string">"Australia"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'Australia'</span><span class="token operator">&gt;</span>
</code></pre>
<p>Using regular expressions, we can also construct a pattern that would validate if the string is a valid variable name in Python. Do you remember what the rules were? It can contain any number of letters numbers or underscores, but it can’t start with a number.</p>
<pre class=" language-python"><code class="prism  language-python">pattern <span class="token operator">=</span> r<span class="token string">"^[a-zA-Z_][a-zA-Z0-9_]*$"</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> <span class="token string">"this_is_a_valid_variable_name"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'this_is_a_valid_variable_name'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> <span class="token string">"this isn't a valid variable name"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token boolean">None</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> <span class="token string">"my_variable1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'my_variable1'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> <span class="token string">"2my_variable_name"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token boolean">None</span>
</code></pre>
<p>Exercise:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
<span class="token keyword">def</span> <span class="token function">check_sentence</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Check if the text passed looks like a standard\
   sentence, meaning that it starts with an uppercase\
    letter, followed by at least some lowercase\
     letters or a space, and ends with a period,\
      question mark, or exclamation point
  """</span>
  result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"^[A-Z]+[a-z0-9]+[.?!$]"</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
  <span class="token keyword">return</span> result <span class="token operator">!=</span> <span class="token boolean">None</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>check_sentence<span class="token punctuation">(</span><span class="token string">"Is this is a sentence?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># True</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>check_sentence<span class="token punctuation">(</span><span class="token string">"is this is a sentence?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># False</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>check_sentence<span class="token punctuation">(</span><span class="token string">"Hello"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># False</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>check_sentence<span class="token punctuation">(</span><span class="token string">"1-2-3-GO!"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># False</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>check_sentence<span class="token punctuation">(</span><span class="token string">"A star is born."</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># True</span>
</code></pre>
<h3 id="regular-expressions-cheat-sheet">Regular Expressions Cheat-Sheet</h3>
<p>List of special characters/metacharacters:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token punctuation">.</span> <span class="token operator">^</span> $ <span class="token operator">*</span> <span class="token operator">+</span> ? <span class="token punctuation">{</span> <span class="token punctuation">}</span> <span class="token punctuation">[</span> <span class="token punctuation">]</span> \ <span class="token operator">|</span> <span class="token punctuation">(</span> <span class="token punctuation">)</span>
</code></pre>
<p>Check out the following links for more information:</p>
<ul>
<li>
<p><a href="https://docs.python.org/3/howto/regex.html">Regular Expression HOWTO</a></p>
</li>
<li>
<p><a href="https://docs.python.org/3/library/re.html">re — Regular expression operations</a></p>
</li>
<li>
<p><a href="https://docs.python.org/3/howto/regex.html#greedy-versus-non-greedy">Greedy versus Non-Greedy</a></p>
</li>
</ul>
<p>Shout out to <a href="http://regex101.com/">regex101.com</a>, which will explain each stage of a regex.</p>
<h2 id="advanced-regular-expressions">Advanced Regular Expressions</h2>
<h3 id="capturing-groups">Capturing Groups</h3>
<p>Up to now, we’ve used the search function to check if a string matched a certain pattern. But the only thing we’ve done with the result is print. Printing is useful when we want to see if a string matches a certain pattern.</p>
<p>But most of the time, we want to take the information that we matched and use it for something else. For example, we may want to extract the hostname or a process ID from a log line and use that value for another operation. For that we need to use a concept of regular expressions called <strong>capturing groups</strong>.</p>
<p><strong>Capturing groups are portions of the pattern that are enclosed in parentheses</strong>.</p>
<p>Example:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"^(\w*), (\w*)$"</span><span class="token punctuation">,</span> <span class="token string">"Lovelace, Ada"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
</code></pre>
<p>The match object has more attributes and methods than the ones shown by print, so we are going to start using them now. Let’s look at the output of the groups method:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>results<span class="token punctuation">.</span>groups<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>$
<span class="token punctuation">(</span><span class="token string">'Lovelace'</span><span class="token punctuation">,</span> <span class="token string">'Ada'</span><span class="token punctuation">)</span>
</code></pre>
<p>Because we defined two separate groups, the group method returns a tuple of two elements. We can also use indexing to access these groups. The first element contains the text matched by the entire regular expression. Each successive element contains the data that was matched by every subsequent match group. So let’s look at the element at index 0.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token string">'Lovelace, Ada'</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token string">'Lovelace'</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token string">'Ada'</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{} {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Nice!</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
<span class="token keyword">def</span> <span class="token function">rearrange_name</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">:</span>
  result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"^(\w*), (\w*)$"</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>
  <span class="token keyword">if</span> result <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> name
  <span class="token keyword">return</span> <span class="token string">"{} {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

name <span class="token operator">=</span> rearrange_name<span class="token punctuation">(</span><span class="token string">"Ritchie, Dennis"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span>
name <span class="token operator">=</span> rearrange_name<span class="token punctuation">(</span><span class="token string">"Thompson, Ken"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span>
</code></pre>
<p><strong>Exercise</strong>: Fix the regular expression used in the rearrange_name function so that it can match middle names, middle initials, as well as double surnames (Tip: keep 2 capturing groups, allow for the second to optionally contain a space, then a group of characters):</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
<span class="token keyword">def</span> <span class="token function">rearrange_name</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">:</span>
  result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"^(\w*), (\w*)$"</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span> <span class="token comment"># "^(\w*), (\w*\ ?\w*.?)$" worked</span>
  <span class="token keyword">if</span> result <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> name
  <span class="token keyword">return</span> <span class="token string">"{} {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

name<span class="token operator">=</span>rearrange_name<span class="token punctuation">(</span><span class="token string">"Kennedy, John F."</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span>
name<span class="token operator">=</span>rearrange_name<span class="token punctuation">(</span><span class="token string">"Hopper, Grace M."</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span>
</code></pre>
<p>Note from the course: <em>Oops! We made a small error. Un-escaped, the dot in this expression will match any character. In this case it makes the code work, but it is incorrect! Since we wanted to match the dot character specifically, we should have escaped the dot in the regular expression. The correct regular expression should be: r"^([\w .-]*), ([\w .-]*)$"</em></p>
<h3 id="more-on-repetition-qualifiers">More on Repetition Qualifiers</h3>
<p>Up to now, we’ve used the Star, Plus and question mark repetition qualifiers. What if we wanted a pattern that repeats a specific number of times? This could happen if we’re processing a line that we know has some specific data in a column, or we know that we want a string of a specific length. In cases like those, we would manually write the same pattern as many times as we need it. But it would be hard to read and hard to maintain. And that’s why Python also offers numeric repetition qualifiers. These are written between curly brackets and can be one or two numbers specifying a range.</p>
<p>For example, to match any string of <strong>exactly</strong> five letters, we can use an expression like this one:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"[a-zA-Z]{5}"</span><span class="token punctuation">,</span> <span class="token string">"a ghost"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'ghost'</span><span class="token operator">&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"[a-zA-Z]{5}"</span><span class="token punctuation">,</span> <span class="token string">"a scary ghost appeared"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'scary'</span><span class="token operator">&gt;</span> <span class="token comment"># only the first\</span>
 occurence <span class="token keyword">is</span> returned
<span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>r<span class="token string">"[a-zA-Z]{5}"</span><span class="token punctuation">,</span> <span class="token string">"a scary ghost appeared"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'scary'</span><span class="token punctuation">,</span> <span class="token string">'ghost'</span><span class="token punctuation">,</span> <span class="token string">'appea'</span><span class="token punctuation">]</span>
</code></pre>
<p>Now we have an extra match for the word that’s actually longer. What if we wanted to match all the words that are exactly five letters long? We can do that using <strong>\b</strong>, which matches word limits at the beginning and end of the pattern, to indicate that we want full words, like this:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>r<span class="token string">"\b[a-zA-Z]{5}\b"</span><span class="token punctuation">,</span> <span class="token string">"A scary ghost appeared"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'scary'</span><span class="token punctuation">,</span> <span class="token string">'ghost'</span><span class="token punctuation">]</span>
</code></pre>
<p>We said that we can also have two numbers in the range. For example, if we wanted to match a range of five to ten letters or numbers, we could use an expression like this one.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>r<span class="token string">"\w{5,10}"</span><span class="token punctuation">,</span> <span class="token string">"I really like strawberries"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'really'</span><span class="token punctuation">,</span> <span class="token string">'strawberri'</span><span class="token punctuation">]</span>
</code></pre>
<p>These ranges can also be open ended. A number followed by a comma means at least that many repetitions with no upper boundary limited only by the maximum repetitions in the source text.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>r<span class="token string">"\w{5,}"</span><span class="token punctuation">,</span> <span class="token string">"I really like strawberries"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'really'</span><span class="token punctuation">,</span> <span class="token string">'strawberries'</span><span class="token punctuation">]</span>
</code></pre>
<p>Now, for our final example, a comma followed by a number means from zero up to that amount of repetitions. Let’s check that one out:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>r<span class="token string">"s\w{,20}"</span><span class="token punctuation">,</span> <span class="token string">"I really like strawberries"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>re<span class="token punctuation">.</span>Match <span class="token builtin">object</span><span class="token punctuation">;</span> span<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">)</span><span class="token punctuation">,</span> match<span class="token operator">=</span><span class="token string">'strawberries'</span><span class="token operator">&gt;</span>
</code></pre>
<p>Exercise:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
<span class="token keyword">def</span> <span class="token function">long_words</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
  pattern <span class="token operator">=</span> ___
  result <span class="token operator">=</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> text<span class="token punctuation">)</span>
  <span class="token keyword">return</span> result

<span class="token keyword">print</span><span class="token punctuation">(</span>long_words<span class="token punctuation">(</span><span class="token string">"I like to drink coffee in the morning."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\
 <span class="token comment"># ['morning']</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>long_words<span class="token punctuation">(</span>"I also have a taste <span class="token keyword">for</span> hot chocolate <span class="token keyword">in</span> the\
 afternoon<span class="token punctuation">.</span>"<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># ['chocolate', 'afternoon']</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>long_words<span class="token punctuation">(</span><span class="token string">"I never drink tea late at night."</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># []</span>
</code></pre>
<h3 id="extracting-a-pid-using-regexes-in-python">Extracting a PID Using regexes in Python</h3>
<p>Remember the example from the beginning of our discussion of regular expressions? It was way back in the first video of this module when we were looking at the log lines and extracting process IDs. Well, we now have enough info to fully understand it. Let’s walk through it step-by-step:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
log <span class="token operator">=</span> "July <span class="token number">31</span> <span class="token number">07</span><span class="token punctuation">:</span><span class="token number">51</span><span class="token punctuation">:</span><span class="token number">48</span> mycomputer bad_process <span class="token punctuation">[</span><span class="token number">54321</span><span class="token punctuation">]</span><span class="token punctuation">:</span>\
 ERROR Performing package upgrade"
regex <span class="token operator">=</span> r<span class="token string">"\[(\d+)\]"</span>
result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>regex<span class="token punctuation">,</span> log<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<p>Let’s try our expression on a different string and check that it really works,<br>
no matter what the rest of the text is:</p>
<pre class=" language-python"><code class="prism  language-python">result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>regex<span class="token punctuation">,</span> "A completely different string that also\
 has numbers <span class="token punctuation">[</span><span class="token number">271274</span><span class="token punctuation">]</span>"<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">271274</span>
</code></pre>
<p>But what if our string didn’t actually have a block of numbers between the square brackets?</p>
<pre class=" language-python"><code class="prism  language-python">result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>regex<span class="token punctuation">,</span> <span class="token string">"99 elephants in a [cage]"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
TypeError<span class="token punctuation">:</span> <span class="token string">'NoneType'</span> <span class="token builtin">object</span> <span class="token keyword">is</span> <span class="token operator">not</span> subscriptable
</code></pre>
<p>We tried to access the index 1 of a variable that was none. As Python tells us, this isn’t something that we can do. So what should we do instead? We should have a function that extracts the process ID or PID when possible, and does something else if not. It’s something like this:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">def</span> <span class="token function">extract_pid</span><span class="token punctuation">(</span>log_line<span class="token punctuation">)</span><span class="token punctuation">:</span>
  regex <span class="token operator">=</span> r<span class="token string">"\[(\d+)\]"</span>
  result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>regex<span class="token punctuation">,</span> log_line<span class="token punctuation">)</span>
  <span class="token keyword">if</span> result <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span> <span class="token comment"># See note</span>
    <span class="token keyword">return</span> <span class="token string">""</span>
  <span class="token keyword">return</span> result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>extract_pid<span class="token punctuation">(</span>"July <span class="token number">31</span> <span class="token number">07</span><span class="token punctuation">:</span><span class="token number">51</span><span class="token punctuation">:</span><span class="token number">48</span> mycomputer bad_process <span class="token punctuation">[</span><span class="token number">54321</span><span class="token punctuation">]</span>\
  <span class="token punctuation">:</span> ERROR Performing package upgrade"<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token number">54321</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>extract_pid<span class="token punctuation">(</span><span class="token string">"99 elephants in a [cage]"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre>
<p><strong>Note</strong>: What we choose to do depends on what we want the rest of the code to do.</p>
<p><strong>Exercise</strong>: Add to the regular expression used in the extract_pid function, to return the uppercase message in parenthesis, after the process id.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> re
<span class="token keyword">def</span> <span class="token function">extract_pid</span><span class="token punctuation">(</span>log_line<span class="token punctuation">)</span><span class="token punctuation">:</span>
    regex <span class="token operator">=</span> r<span class="token string">"\[(\d+)\]: (\b[A-Z]*\b)"</span>
    result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>regex<span class="token punctuation">,</span> log_line<span class="token punctuation">)</span>
    <span class="token keyword">if</span> result <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>
    <span class="token keyword">return</span> <span class="token string">"{} ({})"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> result<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>extract_pid<span class="token punctuation">(</span>"July <span class="token number">31</span> <span class="token number">07</span><span class="token punctuation">:</span><span class="token number">51</span><span class="token punctuation">:</span><span class="token number">48</span> mycomputer bad_process<span class="token punctuation">[</span><span class="token number">12345</span><span class="token punctuation">]</span><span class="token punctuation">:</span>\
 ERROR Performing package upgrade"<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 12345 (ERROR)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>extract_pid<span class="token punctuation">(</span><span class="token string">"99 elephants in a [cage]"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># None</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>extract_pid<span class="token punctuation">(</span>"A string that also has numbers <span class="token punctuation">[</span><span class="token number">34567</span><span class="token punctuation">]</span> but no<span class="token operator">/</span>
uppercase message"<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># None</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>extract_pid<span class="token punctuation">(</span>"July <span class="token number">31</span> <span class="token number">08</span><span class="token punctuation">:</span><span class="token number">08</span><span class="token punctuation">:</span><span class="token number">08</span> mycomputer new_process<span class="token punctuation">[</span><span class="token number">67890</span><span class="token punctuation">]</span><span class="token punctuation">:</span>\
 RUNNING Performing backup"<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 67890 (RUNNING)</span>
</code></pre>
<h3 id="splitting-and-replacing">Splitting and Replacing</h3>
<p>Up to now we’ve been using two functions from the <strong>re</strong> module: <strong>search()</strong> and <strong>findall()</strong>. There are actually a few more functions that can be really handy depending on what we’re trying to do.</p>
<p>One of these functions is called split. It works similarly to the split function that we used before with strings. But instead of taking a string as a separator, you can take any regular expression as a separator. For example we may want to split a piece of text into separate sentences. To do that we need to check not only for the dots but also for question marks or exclamation marks since they’re also valid sentence endings. It’s something like this:</p>
<pre class=" language-python"><code class="prism  language-python">re<span class="token punctuation">.</span>split<span class="token punctuation">(</span>r<span class="token string">"[.!?]"</span><span class="token punctuation">,</span> <span class="token string">"A sentence. Another one? And the last one!"</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'A sentence'</span><span class="token punctuation">,</span> <span class="token string">' Another one'</span><span class="token punctuation">,</span> <span class="token string">' And the last one'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">]</span>
</code></pre>
<p>Check out how we are not escaping the characters that we wrote inside the square brackets. That’s because anything that’s inside the square brackets is taking for the literal character and not for its special meaning. Also see how the notation marks aren’t present in the resulting list.</p>
<p>If we want our split list to include the elements that we’re using to split the values we can use capturing parentheses like this:</p>
<pre class=" language-python"><code class="prism  language-python">re<span class="token punctuation">.</span>split<span class="token punctuation">(</span>r<span class="token string">"([.!?])"</span><span class="token punctuation">,</span> <span class="token string">"A sentence. Another one? And the last one!"</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'A sentence'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">' Another one'</span><span class="token punctuation">,</span> <span class="token string">'?'</span><span class="token punctuation">,</span> <span class="token string">' And the last one'</span><span class="token punctuation">,</span> <span class="token string">'!'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">]</span>
</code></pre>
<p>Another interesting function provided by the RE module is called sub. It’s used for creating new strings by substituting all or part of them for a different string, similar to the replace string method but using regular expressions for both the matching and the replacing. Let’s see this in an example.</p>
<pre class=" language-python"><code class="prism  language-python">re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>r<span class="token string">"[\w.%+-]+@[\w.-]+"</span><span class="token punctuation">,</span> <span class="token string">"[REDACTED]"</span><span class="token punctuation">,</span> "Got an email <span class="token keyword">for</span>\
 user@host<span class="token punctuation">.</span>name"<span class="token punctuation">)</span>
<span class="token string">'Got an email for [REDACTED]'</span>
</code></pre>
<p>The expression that we’re using for identifying email addresses has two parts: the part before that at sign and the part after it. Check out the part that comes before the at sign. We include the alphanumeric characters represented by backslash w which includes letters, numbers, and the underscore sign as well as a dot, percentage sign, plus, and dash. After the at sign, we only allow the alphanumeric characters dot and dash. This will match all email addresses as well as some strings that aren’t really valid email addresses like an address with two dots. In this scenario we want to be better safe than sorry. So we’re going to redact anything that looks like an address. If we wanted to validate that the address is an actual email we would need to be a lot stricter.</p>
<p>Let’s now look at an example using sub where we use regular expressions for the replacing. For that, we’ll go back to our code that switched the order of names of people and use sub to create the new string.</p>
<pre class=" language-python"><code class="prism  language-python">re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>r<span class="token string">"^([\w .-]*), ([\w .-]*)$"</span><span class="token punctuation">,</span> r<span class="token string">"\2 \1"</span><span class="token punctuation">,</span> <span class="token string">"Lovelace, Ada"</span><span class="token punctuation">)</span>
<span class="token string">'Ada Lovelace'</span>
</code></pre>
<p>When referring to captured groups, a backslash followed by a number indicates the corresponding captured group. This is a general notation for regular expressions, and it’s used by many tools that support regexes, not just Python.</p>
<p>We can also use them to match patterns that repeat themselves which use capturing groups as back references. We won’t look into them here, but if you want to learn more, you’ll find a bunch more info about them online.</p>
<h3 id="advanced-regular-expressions-cheat-sheet">Advanced Regular Expressions Cheat-Sheet</h3>
<p>Check out the following link for more information:</p>
<ul>
<li><a href="https://regexcrossword.com/">Regex Cross­word</a></li>
</ul>
<h2 id="managing-data-and-processes">Managing Data and Processes</h2>
<h3 id="data-streams">Data Streams</h3>
<h3 id="reading-data-interactively">Reading Data interactively</h3>
<p>We’ve talked before about reading and writing files. Using files to store information and then processing that data over a script is a great way to build automation. But sometimes we need to interact with the user and ask them for certain pieces of information that just can’t be stored in a file. To do this Python provides a function called <strong>input</strong>. This function allows us to prompt the user for a certain value that we can then use for our scripts. Let’s see what that looks like.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env/ python3</span>

name <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"Please enter your name: "</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Hello, "</span> <span class="token operator">+</span> name<span class="token punctuation">)</span>
</code></pre>
<p>Also see to_seconds.py</p>
<h3 id="standard-streams">Standard Streams</h3>
<p>We’ve now seen a couple ways of getting information into and out of our scripts. We know how to read and write to files and accept input from the keyword and print it to the screen, too. But what exactly is going on behind the scenes when we do this? How does a Python program connect to both the screen and the keyboard? Well, it uses I/O streams. <strong>I/O streams</strong> are the basic mechanism for performing input and output operations in your programs.</p>
<p>We call these streams because the data keeps flowing. A program can read input and<br>
generate output as long as it needs to achieve its goal. What do these streams mean in practice?</p>
<p>Most operating systems supply three different I/O streams by default each with<br>
a different purpose</p>

<table>
<thead>
<tr>
<th>Standard Stream</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Standard Input stream or “STDIN”</td>
<td>Usually in the form of text data from the keyboard</td>
</tr>
<tr>
<td>Standard Output stream or “STDOUT”</td>
<td>Generally takes the form of text displayed in a terminal</td>
</tr>
<tr>
<td>Standard Error or “STDERR”</td>
<td>Displays output like standard out, but is used specifically as a channel to show error messages and diagnostics from the program</td>
</tr>
</tbody>
</table><h3 id="environment-variables">Environment Variables</h3>
<p>When we open a terminal application on a Linux computer, whether it’s local or a remote machine, the application that reads and executes all commands is called a <strong>shell</strong>. A shell is a command line interface used to interact with your operating system.</p>
<p>Python programs get executed inside a shell command-line environment. The variables set in that environment which are called <strong>environment variables</strong> and are another source of information that we can use in our scripts.</p>
<p>We can read the contents of these variables from Python. Let’s use a Python script to check that out:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>
<span class="token comment"># script name: variables.py</span>
<span class="token keyword">import</span> os

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"HOME: "</span> <span class="token operator">+</span><span class="token punctuation">)</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"HOME"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"SHELL: "</span> <span class="token operator">+</span><span class="token punctuation">)</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"SHELL"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"FRUIT: "</span> <span class="token operator">+</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"FRUIT"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>To access environment variables, we use the environ dictionary provided by the OS module. In this case, we’re using a dictionary method that we haven’t used before.</p>
<p>The getMethod is a bit similar to how we’ve been accessing dictionary values up until now. The difference is what happens when the value isn’t present. When we retrieve a value from a dictionary using the key as in OS.environ[fruit] and the key isn’t present, we get an error.</p>
<p>If we use a getMethod instead, we can specify what value should be returned if the key isn’t present. In other words, the getMethod allows us to specify a default value when the key that we’re looking for isn’t in the dictionary. So what we’re asking Python to do is try to retrieve the value associated with the key, but if the key’s not defined return an empty string instead. We’re doing this for three different variables; home, shell, and fruit. Let’s run the script and see what happens.</p>
<p>We define the variable by just setting a value using the equal sign and leaving no spaces in between. Along with this, the export keyword tells a shell that we want the value we set to be seen by any commands that we call.</p>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token function">export</span> FRUIT<span class="token operator">=</span>Pineapple
</code></pre>
<p>We can now rerun our <a href="http://variables.py">variables.py</a> script to check the value of the FRUIT environment variable.</p>
<h3 id="command-line-arguments-and-exit-status">Command-Line Arguments and Exit Status</h3>
<p>Up to now, we’ve seen how different programs can read from and write to standard IO streams and how the show environment can influence execution of a program. Yet another common way of providing information to our programs is through command line arguments.</p>
<p>Command-line arguments are parameters that are passed to a program when it started. It’s a super common practice to make our scripts receive certain values by command line arguments. It allows a code of the script to be generic while also letting us run it automatically without requiring any interactive user input. This means that these arguments are really useful for system administration tasks. That’s because we can specify the information that we want our program to use before it even starts.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>
<span class="token comment"># Script name: parameters.py</span>

<span class="token keyword">import</span> sys

<span class="token keyword">print</span><span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>
</code></pre>
<p>Our script just imports the sys module and prints the sys.argv list. Now, let’s see what happens when we call the program.</p>
<pre class=" language-bash"><code class="prism  language-bash">./parameters.py
<span class="token punctuation">[</span><span class="token string">'./parameters.py'</span><span class="token punctuation">]</span>
</code></pre>
<p>In this case, we called the script without any parameters. The list contains one single element. The name of the program that we just executed. Let’s try passing a few parameters.</p>
<pre class=" language-bash"><code class="prism  language-bash">./parameters.py one two three
<span class="token punctuation">[</span><span class="token string">'./parameters.py'</span>, <span class="token string">'one'</span>, <span class="token string">'two'</span>, <span class="token string">'three'</span><span class="token punctuation">]</span>
</code></pre>
<p>Last up we have the concept of <strong>exit status</strong> or <strong>return code</strong>, which provides another source of information between the shell and the programs that get executed inside of it.</p>
<p>The exit status is a value returned by a program to the shell. In all Unix-like operating systems, the exit status of the process is zero when the process succeeds and different than zero if it fails.</p>
<p>The actual number returned gives additional info on what kind of error the program encountered. Knowing if a command finished successfully or not is helpful information which can be used by a program that’s calling a command.</p>
<p>For example, it can use the information to retry the command. If it failed. To check the exit status of a program, we can use a special variable that lets us see what the exit status of the last executed command was.</p>
<p>The variable is the <strong>question mark variable</strong>. So to see the contents we use dollar sign question mark. Let’s try this out using the WC command, which counts the number of lines words and characters in a file. First, we’ll pass it our <a href="http://variables.py">variables.py</a> Script and check the exit value.</p>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token function">wc</span> variables.py
       7      21     200 variables.py
<span class="token keyword">echo</span> <span class="token variable">$?</span>
0
<span class="token function">wc</span> notpresent.file
wc: notpresent.file: open: No such <span class="token function">file</span> or directory
<span class="token keyword">echo</span> <span class="token variable">$?</span>
1
</code></pre>
<p>Here, <strong>wc</strong> couldn’t run for the file that we pass because it doesn’t exist. The command printed an error and when printing the contents of the dollar sign question mark variable, we see that it finished with an exit value of one.</p>
<p>So that’s with system commands, but what about Python scripts? When a Python script finishes successfully, it exits with an exit value of zero. When it finishes with an error like type error or value error, it exits with a different value than zero. We can make it exit with whatever value is relevant.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>
<span class="token comment"># Script name: create_file.py</span>
<span class="token keyword">import</span> os
<span class="token keyword">import</span> sys

fielname <span class="token operator">=</span> sys<span class="token punctuation">.</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

<span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"New file created\n"</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Error: the file {} already exists!"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">)</span>
  sys<span class="token punctuation">.</span>exit<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre>
<p>To try this out let’s first execute the script and pass a file that doesn’t exist:</p>
<pre class=" language-bash"><code class="prism  language-bash">./create_file.py example
<span class="token keyword">echo</span> <span class="token variable">$?</span>
0
<span class="token function">cat</span> example
New <span class="token function">file</span> created
./create_file example
Error: the <span class="token function">file</span> example already exists<span class="token operator">!</span>
<span class="token keyword">echo</span> <span class="token variable">$?</span>
1
</code></pre>
<p>See the “More About Input Functions” addendum file.</p>
<h2 id="python-subprocesses">Python Subprocesses</h2>
<h3 id="running-system-commands-in-python">Running System Commands in Python</h3>
<p>Up to now, we’ve been using Python to interact with the operating system through baked in functionality. For example, we’ve used file objects to read the contents of files, used the <strong>shutil</strong> module to check if the disk is full. And use a <strong>sys</strong> module to process standard input, get parameters, or generate an exit code.</p>
<p>But what if we needed to run a system program from a Python script?</p>
<p>Say, for example, that as part of a Python script, we needed to send ICMP packets to a host to check if it’s responding. We could try to look for an external module that provides this functionality. Or we can just run the <strong>ping</strong> command, which will send packets for us. Sometimes it’s easier or faster to use a system command as part of our Python script to accomplish a task, or use some functionality that doesn’t exist in the Python modules, neither built-in or external.</p>
<p>For these cases, Python provides a way to execute system commands in our scripts, using functions provided by the subprocess module. Let’s check out an example:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> subprocesses

<span class="token keyword">print</span><span class="token punctuation">(</span>subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"date"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
Mar <span class="token number">27</span> déc <span class="token number">2022</span> <span class="token number">17</span><span class="token punctuation">:</span><span class="token number">31</span><span class="token punctuation">:</span><span class="token number">10</span> CET
CompletedProcess<span class="token punctuation">(</span>args<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'date'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> returncode<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"sleep"</span><span class="token punctuation">,</span> <span class="token string">"3"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
CompletedProcess<span class="token punctuation">(</span>args<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'sleep'</span><span class="token punctuation">,</span> <span class="token string">'3'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> returncode<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

result <span class="token operator">=</span> subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"ls"</span><span class="token punctuation">,</span> <span class="token string">"this_file_does_not_exist"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
ls<span class="token punctuation">:</span> this_file_does_not_exist<span class="token punctuation">:</span> No such <span class="token builtin">file</span> <span class="token operator">or</span> directory
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>returncode<span class="token punctuation">)</span>
</code></pre>
<h3 id="obtaining-the-output-of-a-system-command">Obtaining the Output of a System Command</h3>
<p>If we want our Python scripts to manipulate the output of system command that we’re executing, we need to tell the run function to capture it for us. This might be helpful when we need to extract information from a command and then use it for something else in our script.</p>
<p>For example, say you want to create some stats on which users are logging into a server throughout the day. You could do this with a script that calls the <strong>who</strong> command, which prints the users currently logged into a computer. The script could parse the output of the command, storing the list of logged-in users once per hour and at the end of the date to generate a daily report.</p>
<p>To be able to process the output of commands, we’ll set a parameter called capture_output to true when calling the run function (requires Python 3.7 or later). For our next example, we’ll call the <strong>host</strong> command, which can convert a host name to an IP address and vice versa. When calling it, we’ll pass the capture output equals true parameter and store the result in a variable so that we can access it. Let’s give it a try:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> subprocess

result <span class="token operator">=</span> subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"host"</span><span class="token punctuation">,</span> <span class="token string">"8.8.8.8"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> capture_output<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>returncode<span class="token punctuation">)</span> <span class="token comment"># we can check the return code attribute like before</span>
<span class="token number">0</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
b<span class="token string">'8.8.8.8.in-addr.arpa domain name pointer dns.google.\n'</span>
</code></pre>
<p>What’s that “b” at the beginning of the string? Well, that B tells us that this string is not a proper string for Python. It’s actually an array of bytes, and this is a complex subject.</p>
<ul>
<li><em>Data in computers is stored and transmitted in bytes and each can represent up to 256 characters. But there are thousands of possible characters out there used to write in various languages. Chinese, for example, requires over 10,000 different characters. To be able to write in those languages, several specifications called encodings have been created over time to indicate which sequences of bytes represent which characters. Nowadays, most people use <strong>UTF-8</strong> encoding, which is part of the Unicode standard that lists all the possible characters that can be represented.</em></li>
</ul>
<p>So going back to our example when we execute the command using run, Python doesn’t know which encoding to use to process the output of the command. So it simply represents it as a series of bytes. If we want this to become a proper string, we can call the <strong>decode</strong> method. This method applies an encoding to transform the bytes into a string. By default, it uses a UTF-8 encoding which is what we want. So with all that said, let’s transform our array of bytes into a string and then split it into several pieces:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'8.8.8.8.in-addr.arpa'</span><span class="token punctuation">,</span> <span class="token string">'domain'</span><span class="token punctuation">,</span> <span class="token string">'name'</span><span class="token punctuation">,</span> <span class="token string">'pointer'</span><span class="token punctuation">,</span> <span class="token string">'dns.google.'</span><span class="token punctuation">]</span>
</code></pre>
<p>We just looked at the captured standard output. But what about standard error? If we use the capture_output parameter and the command writes any output to standard error, it will be stored in the <strong>stderr</strong> attribute of the completed process instance. Let’s look at an example of this. We’ll try executing the rm command, which we use for removing files passing a filename that doesn’t exist:</p>
<pre class=" language-python"><code class="prism  language-python">result <span class="token operator">=</span> subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"rm"</span><span class="token punctuation">,</span> <span class="token string">"file_that_does_not_exist"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> capture_output<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>returncode<span class="token punctuation">)</span>
<span class="token number">1</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
b<span class="token string">''</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
b<span class="token string">'rm: file_that_does_not_exist: No such file or directory\n'</span>
</code></pre>
<p>We’ve now seen that we can execute system commands from Python and check whether they succeeded or failed. We’ve also seen how to capture the standard output and standard error streams so we can use their content in our scripts. These skills can be super useful when writing scripts that your system commands for some involved task and letting our Python scripts cover a broader range of tasks.</p>
<h3 id="advanced-subprocess-management">Advanced Subprocess Management</h3>
<p>We’ve seen how to run system commands from Python, how to check the exit value, and how to manipulate the normal output and error output of the command. The sub process module offers a lot of extra options that we can use in our scripts.</p>
<p>For example, we called out in an earlier video that one way of providing information to our processes is to modify the environment variables. Using this mechanism, we can change where the process looks for executable files, which commands it uses interact with some parts of the system, the kind of output it’ll generate and a bunch more things.</p>
<p>The usual strategy for modifying the environment of a child process is to first copy the environment seen by our process, do any necessary changes, and then pass that as the environment that the child process will see. Let’s take a look at this:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> subprocess

my_env <span class="token operator">=</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
my_env<span class="token punctuation">[</span><span class="token string">"PATH"</span><span class="token punctuation">]</span> <span class="token operator">=</span> os<span class="token punctuation">.</span>pathsep<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"/opt/myapp"</span><span class="token punctuation">,</span> my_env<span class="token punctuation">[</span><span class="token string">"PATH"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

result <span class="token operator">=</span> subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"my_app"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> env <span class="token operator">=</span> my_env<span class="token punctuation">)</span>
</code></pre>
<p>To recap, this script is modifying the contents of the path environment variable by adding a directory to it. We then call the myapp command with that modified variable. Doing it this way, the command will run in the modified environment with the updated value of path.</p>
<p>There are a bunch more options that we can use with the run function. For example, we can use the <strong>cwd</strong> parameter to change the current working directory where the command will be executed. This can be really helpful when working with a set of directories where you need to run a command on each of them.</p>
<p>We could also set the <strong>timeout</strong> parameter. This will cause the run function to kill the process if it takes longer than a given number of seconds to finish. This might be useful if you’re running a command that you know might get stuck. For example, if it’s trying to connect to a network and your computer is offline.</p>
<p>Or we can also set the <strong>shell</strong> parameter. If we set this to true, Python will first execute an instance of the default system shell and then run the given command inside of it. This means our command line could include variable expansions and other shell operations. Without the shell parameter, this would not be possible.</p>
<p>We’ll learn more about the things that we can do with the shell later in this course. For now, just keep in mind that if you need to expand variables or globs, you’ll need to set this parameter.</p>
<p>But using this can be a security risk. So make sure you actually need it and be careful when using it if you do. Before we finish our discussion of the subprocess module, a word of caution.</p>
<p>Interfacing the underlying system directly in your Python scripts via subprocesses and system commands can be useful especially if you need to do a specific task quickly. But it comes with some drawbacks. Using these system-level commands built assumptions into our scripts about the infrastructure, our automation will run on. If those assumptions change, it can lead to unexpected effects or failures. These kinds of assumptions can change in multiple ways.</p>
<p>What would happen to our automation is the flags where terminal command change and our script continues to use the old flags? What happens if we switch operating systems from Linux to Windows? Will our scripts fail outright or will they succeed in unintended and possibly harmful ways?</p>
<p>Any change to the system or external commands our scripts use increases the chances of something breaking. Sometimes that break might be obvious and other times it might be difficult to detect.</p>
<ul>
<li>
<p>If we’re automating a one-off, well-defined task, we’re developing a solution quickly is the biggest requirement, then using system commands and subprocesses can help a lot.</p>
</li>
<li>
<p>But if we’re doing something more complex or long-running, it’s usually a good idea to use the baked-in or external modules that Python provides. So before deciding to use a sub processes, it’s a good idea to check the standard library or pypi repository to see if we can do the task with native Python and to check if someone has already created the automation that we wanted to write.</p>
</li>
</ul>
<p>Remember that we never want to reinvent the wheel.</p>
<h3 id="python-subprocesses-cheat-sheet">Python Subprocesses Cheat Sheet</h3>
<p>Check out the following link for more information:</p>
<ul>
<li><a href="https://docs.python.org/3/library/subprocess.html">https://docs.python.org/3/library/subprocess.html</a></li>
</ul>
<h2 id="processing-log-files">Processing Log Files</h2>
<h3 id="what-are-log-files">What are log files?</h3>
<p>Now we’re going to take a look at how we can use these tools to help us with our day-to-day work. In the next few videos, we’ll dive into a concrete examples centered around processing chunks of data. The kind of data that you might find in a Syslog file or a web request log. The different events that happen in programs that are running in a system and aren’t connected to terminal are usually rendered to log files. Log files contain a lot of useful information, particularly when you’re trying to debug a tricky problem that’s happening on a computer.</p>
<p>On the flip side, sometimes it can be overwhelming to try to find something inside of a log file that contains a whole lot of lines with a whole lot of things in them.</p>
<p>So it’s a good idea to learn how we can process these files and get our tools to extract information that we want out of them. To do this we’ll go back to our knowledge of regular expressions. Using regex’s in our scripts gives us a great deal of flexibility when processing log files and other texts data sources too. In a script, we can program any kind of behavior we want, so we can manipulate and process text data and get results we need.</p>
<h3 id="filtering-log-files-with-regular-expressions">Filtering Log Files with Regular Expressions</h3>
<p>When working with log files and scripts, our first step is usually to open them so our code can access their contents. We’ve discussed various methods of operating on files. The usual technique is to call the open function which returns a file object and then iterate through each of its lines using a for-loop.</p>
<p>Remember that for performance reasons, when files are large, it’s generally a good practice to read them line by line instead of loading the entire contents into memory.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>
<span class="token keyword">import</span> re
<span class="token keyword">import</span> sys

logfile <span class="token operator">=</span> sys<span class="token punctuation">.</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>logfile<span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
  <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token string">"CRON"</span> <span class="token operator">not</span> <span class="token keyword">in</span> line<span class="token punctuation">:</span>
      <span class="token keyword">continue</span>
    pattern <span class="token operator">=</span> r<span class="token string">"USER \((\w+)\)$"</span>
    result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> line<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="making-sense-out-of-the-data">Making Sense out of the Data</h3>
<p>We just wrote a script that processed a log file and extracted the names of each user who had started a cron job in the machine that we were investigating. This can be really helpful but there’s more information that we might need.</p>
<p>To improve our output, it would be a good idea to have a count of how many times each username appears in our log. As we’ve seen in earlier examples, dictionaries are great structure to use when we want to count appearances of strings.</p>
<p>We’ll store the user name as a keys of a dictionary and we’ll use the value to count the number of times that each user name appears in the file. To do this in fewer lines, we’ll use the get method that we saw earlier.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>
<span class="token keyword">import</span> re
<span class="token keyword">import</span> sys

logfile <span class="token operator">=</span> sys<span class="token punctuation">.</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
usernames <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>logfile<span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
  <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token string">"CRON"</span> <span class="token operator">not</span> <span class="token keyword">in</span> line<span class="token punctuation">:</span>
      <span class="token keyword">continue</span>
    pattern <span class="token operator">=</span> r<span class="token string">"USER \((\w+)\)$"</span>
    result <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> line<span class="token punctuation">)</span>
    <span class="token keyword">if</span> result <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span> <span class="token comment"># Checks if the rexgex found a match in the current line</span>
      <span class="token keyword">continue</span> <span class="token comment"># and continues on to the next one if not</span>
    name <span class="token operator">=</span> result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    usernames<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> usernames<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>usernames<span class="token punctuation">)</span>
</code></pre>
<h2 id="testing-in-python">Testing in Python</h2>
<h3 id="simple-tests">Simple Tests</h3>
<h3 id="what-is-testing">What is testing?</h3>
<p>When you’re writing a very simple piece of code, say for example, that you’re adding two variables, it’s pretty straightforward to know what the code does, and be sure they’d does it correctly. As operations become more complex using loops, conditionals, calling more and more functions, it’s harder to really be confident that the code will do what it’s supposed to. This is where software testing comes into play.</p>
<p><strong>Software testing</strong> is the process of evaluating computer code to determine whether or not it does what you expect it to do.</p>
<p>When you test a piece of software, you want to find the errors and defects and see where things go wrong. Software testing is similar in lots of ways to the tests performed in the manufacturing process of a new piece of machinery.</p>
<p>Scripts and programs can fail in all sorts of strange ways, especially as it become more complicated. In all but those simple programs, it’s next to impossible to test for everything that could go wrong. Even though this means that a certain number of bugs might exist in your scripts without you realizing it, don’t worry.</p>
<p>Writing tests can help you eliminate a whole bunch of bugs, helping to improve the reliability and the quality of automation. <strong>Tests can help make good code great</strong>. The field of software testing is pretty broad. In the next few sections we’ll explore some fundamental concepts involved like <strong>automated testing</strong>, <strong>unit test</strong>, <strong>integration test</strong>, and <strong>test-driven development</strong>.</p>
<p>As of lots of topics covered in this course, we’ll do a quick rundown of the many concepts around testing. It won’t be enough instructions for you to become a testing expert, but it should help you with automatically testing your scripts.</p>
<h3 id="manual-testing-and-automated-testing">Manual Testing and Automated Testing</h3>
<p>One of the tasks that programmers had to do when writing code is test it to make sure that it behaves the way that they expected to. Having good tests for our software can help us catch mistakes, errors, and bugs before we deploy our scripts to perform real-world automation tasks.</p>
<ul>
<li>
<p>The most basic way of testing a script is to run it with different parameters and see if it returns the expected values. We’ve done this manual testing for some of the code that we’ve written this course already. Executing a script with different command-line arguments to see how its behavior changed is an example of manual testing.</p>
</li>
<li>
<p>Using the interpreter to try our code before putting it in a script is another form of manual testing.</p>
</li>
</ul>
<p>Formal software testing takes us process a step further, codifying tests into its own software and code that can be run to verify that our programs do what we expect them to do. This is called <strong>automatic testing</strong>. The goal of automatic testing is to automate the process of checking if the returned value matches the expectations.</p>
<p><em>Why would you write more code to test code you have?</em></p>
<p>Because when you’re testing your code, you want to check if it does what it’s supposed to do for a lot of different values. You ought to verify that it behaves the way you expect it to have as many possible values known as <strong>test cases</strong>.</p>
<h2 id="unit-tests">Unit Tests</h2>
<p>As we mentioned, there are lots of different types of test that we can write to perform automatic testing. The most common type is a unit test. Unit tests are used to verify that small isolated parts of a program are correct.</p>
<p>As we mentioned, there are lots of different types of test that we can write to perform automatic testing. The most common type is a <strong>unit test</strong>.</p>
<p><strong>Unit tests</strong> are used to verify that small isolated parts of a program are correct.</p>
<p>Unit tests are generally written alongside the code to test the behavior of individual pieces or units like functions or methods. Unit tests help assure the developer that each piece of code does what it’s meant to do.</p>
<p>An important characteristic of a unit test is <strong>isolation</strong>. Unit test should only test the unit of code they target, the function or method that’s being tested. This ensures that any success or failure of the test is caused by the behavior of the unit in question and doesn’t result from some external factor like the network being down or a database server being unresponsive.</p>
<p>In other words, when testing a function or method, we want to make sure that we’re focusing on checking that the code in that function or method behaves correctly. We don’t want our test to fail for external reasons.</p>
<p>Unrelated note, our <strong>tests should never modify the production environment</strong>. This is a live environment that runs a software that users interact with. When developing test, if for any reason we do need to interact with some other software, we’ll normally do that in a <strong>test environment</strong>, where we’ll have control over how it behaves. <strong>It’s our house, our rules</strong>.</p>
<p>So the goal of the unit test is to verify that small, isolated parts of a program are correct. How do we do that? It generally boils down to a simple pattern. Given a known input, does the output of our code match our expectations?</p>
<p>Let’s take a piece of code similar to what we wrote awhile back to rearrange a name in the format last name comma first name and think about how we test it. How do you think we can test that it works the way you’d expect it to? Let’s start by manually validating that for a given input, it produces expected result. We’ll check this by importing the function in an interpreter. To do that, we’ll use a keyword that we haven’t seen before, <strong>from</strong>:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#In a Python interpreter:</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token keyword">from</span> rearrange <span class="token keyword">import</span> rearrange_name
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>rearrange_name<span class="token punctuation">(</span><span class="token string">"Lovelace, Ada"</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token string">'Ada Lovelace'</span>
</code></pre>
<h3 id="writing-unit-tests-in-python">Writing Unit Tests in Python</h3>
<p>We’ve now looked at the principles behind automatic testing. We know that by having automatic tests, we can run them as many times as necessary to make sure that our code does what we want it to do.</p>
<p>So how we do this in Python? We need to write some code that runs a test and verifies the output. This way, we can get our computer to do the work for us. To demonstrate the testing workflow, we’ll create unit tests for the rearrange_name function from the previous section.</p>
<p>As we touched on earlier, automatic tests are usually written alongside the code that we want to test. What this means in practice is creating a separate Python file with the test. <strong>The convention is to call the script with the same name of the module that it’s testing and appending the suffix _test</strong>. So for our rearrange module, we’ll create the rearrange_test.py file.</p>
<p>To help us with the actual writing of the test, Python provides a module called unittest. Thanks Python! This module includes a number of classes and methods that let us easily create unit tests for our code.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>
<span class="token comment"># Script name: rearrange_test.py</span>
<span class="token keyword">from</span> rearrange <span class="token keyword">import</span> rearrange_name
<span class="token keyword">import</span> unittest

<span class="token keyword">class</span> <span class="token class-name">TestRearrange</span><span class="token punctuation">(</span>unittest<span class="token punctuation">.</span>TestCase<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">test_basic</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    testcase <span class="token operator">=</span> <span class="token string">"Lovelace, Ada"</span>
    expected <span class="token operator">=</span> <span class="token string">"Ada Lovelace"</span>
    self<span class="token punctuation">.</span>assertEqual<span class="token punctuation">(</span>rearrange_name<span class="token punctuation">(</span>testcase<span class="token punctuation">)</span><span class="token punctuation">,</span> expected<span class="token punctuation">)</span>

unittest<span class="token punctuation">.</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>All right, we’re ready to run the test. We’ll do that by executing the file that we just created. Let’s make our script executable (with chmod +x) and then run it:</p>
<pre class=" language-bash"><code class="prism  language-bash">./rearrange_test.py
<span class="token keyword">.</span>
----------------------------------------------------------------------
Ran 1 <span class="token function">test</span> <span class="token keyword">in</span> 0.000s

OK
</code></pre>
<p>Looks good! The output is pretty descriptive, printing out some information<br>
about how long a group of tests or <em><strong>test suite</strong></em> took to run, as well as the number of tests, and whether or not, they passed.</p>
<h3 id="edge-cases">Edge Cases</h3>
<p>By now we know how to write automatic tests in Python. Our test suite includes only one test case though. We need to make it grow. Choosing test cases can be an exercise in creativity. Coming up with different ways a piece of code might break can actually be super fun.</p>
<p>We’ll usually test that our code works in general case. But we should also see what happens when we give it some input that we may not expect it to run into under normal operations. For example, what would happen in our function if we gave it an empty string? Let’s add a test for that and see:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>
<span class="token comment"># Script name: rearrange_test.py</span>
<span class="token keyword">from</span> rearrange <span class="token keyword">import</span> rearrange_name
<span class="token keyword">import</span> unittest

<span class="token keyword">class</span> <span class="token class-name">TestRearrange</span><span class="token punctuation">(</span>unittest<span class="token punctuation">.</span>TestCase<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">test_basic</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    testcase <span class="token operator">=</span> <span class="token string">"Lovelace, Ada"</span>
    expected <span class="token operator">=</span> <span class="token string">"Ada Lovelace"</span>
    self<span class="token punctuation">.</span>assertEqual<span class="token punctuation">(</span>rearrange_name<span class="token punctuation">(</span>testcase<span class="token punctuation">)</span><span class="token punctuation">,</span> expected<span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">test_empty</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    testcase <span class="token operator">=</span> <span class="token string">""</span>
    expected <span class="token operator">=</span> <span class="token string">""</span>

unittest<span class="token punctuation">.</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p><strong>Edge cases</strong> are inputs to our code that produce unexpected results, and are found at the extreme ends of the ranges of input we imagine our programs will typically work with.</p>
<p>Edge cases usually need special handling in scripts in order for the code to continue to behave correctly.</p>
<p>Whether or not we handle this kind of error depends on how we want the scripts to behave. In our specific case, returning the original value makes sense when we can’t rearrange it.</p>
<p>But sometimes you might actually want your program to crash with an error rather than to go on as if nothing happened.</p>
<p><strong>Remember that it’s bad for automation to fail silently</strong>.</p>
<p>Other kinds of edge cases usually include things like passing zero to a function that expects a number, or negative numbers, or extremely large numbers. These types of conditions are good to consider when writing your test, since they can cause your code to crash or behave in unexpected ways. Sometimes it pays to be a pessimist. You can see how it might require some creativity to come up with these examples. The upside is that when writing automatic tests, once you’ve come up with example, it’s there to stay.</p>
<h3 id="additional-test-cases">Additional Test Cases</h3>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>
<span class="token comment"># Script name: rearrange_test.py</span>
<span class="token keyword">from</span> rearrange <span class="token keyword">import</span> rearrange_name
<span class="token keyword">import</span> unittest

<span class="token keyword">class</span> <span class="token class-name">TestRearrange</span><span class="token punctuation">(</span>unittest<span class="token punctuation">.</span>TestCase<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">test_basic</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    testcase <span class="token operator">=</span> <span class="token string">"Lovelace, Ada"</span>
    expected <span class="token operator">=</span> <span class="token string">"Ada Lovelace"</span>
    self<span class="token punctuation">.</span>assertEqual<span class="token punctuation">(</span>rearrange_name<span class="token punctuation">(</span>testcase<span class="token punctuation">)</span><span class="token punctuation">,</span> expected<span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">test_empty</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    testcase <span class="token operator">=</span> <span class="token string">""</span>
    expected <span class="token operator">=</span> <span class="token string">""</span>
    self<span class="token punctuation">.</span>assertEqual<span class="token punctuation">(</span>rearrange_name<span class="token punctuation">(</span>testcase<span class="token punctuation">)</span><span class="token punctuation">,</span> expected<span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">test_double_name</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    testcase <span class="token operator">=</span> <span class="token string">"Hopper, Grace M."</span>
    expected <span class="token operator">=</span> <span class="token string">"Grace M. Hopper"</span>
    self<span class="token punctuation">.</span>assertEqual<span class="token punctuation">(</span>rearrange_name<span class="token punctuation">(</span>testcase<span class="token punctuation">)</span><span class="token punctuation">,</span> expected<span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">test_one_name</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    testcase <span class="token operator">=</span> <span class="token string">"Voltaire"</span>
    expected <span class="token operator">=</span> <span class="token string">"Voltaire"</span>
    self<span class="token punctuation">.</span>assertEqual<span class="token punctuation">(</span>rearrange_name<span class="token punctuation">(</span>testcase<span class="token punctuation">)</span><span class="token punctuation">,</span> expected<span class="token punctuation">)</span>

unittest<span class="token punctuation">.</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>One of the great things about running tests in a suite like this, is that we now know that all the test cases we wrote were handled correctly. Our code works for basic names, empty strings, double names, and single names. If we found another case that made our tests break, we could add it to the suite, fix the bug, and then run the whole suite again, being assured that all the other cases are still working.</p>
<h2 id="other-tests-concepts">Other Tests Concepts</h2>
<h3 id="black-box-vs.-white-box">Black Box vs. White Box</h3>
<p>There are lots of different tests that we can use to make sure our software is behaving how we expect it to. We’ve explored unit test in detail which are both simple to write and are very powerful way to catch bugs. But there’s a lot more to software testing. One interesting concept is whether our test is a <strong>white-box test or a black-box test</strong>.</p>
<ul>
<li>
<p><strong>White-box testing</strong> also sometimes called <strong>clear-box</strong> or <strong>transparent testing</strong> relies on the test creators knowledge of the software being tested to construct the test cases.</p>
</li>
<li>
<p><strong>Black-box tests</strong> are written with an awareness of what the program is supposed to do, its requirements or specifications, but not how it does it.</p>
</li>
</ul>
<p>Both white-box and black-box tests have their own advantages.</p>
<p>White-box tests are helpful because a test writer can use their knowledge of the source code to create tests that cover most of the ways that the program behaves. Black-box tests are useful because they don’t rely on the knowledge of how the system works. This means their test cases are less likely to be biased by the code. They usually cover situations not anticipated by the programmer who originally wrote the script.</p>
<p>Not all tests that we write needs to fall to one category or the other. We can write unit tests that are either white or black-box, depending on which testing methodology is chosen.</p>
<ul>
<li>
<p>If the unit tests are created before any code is written based on specifications of what the code is supposed to do, they can be considered black-box unit test.</p>
</li>
<li>
<p>If unit tests are run alongside or after the code has been developed, the test cases are made with a knowledge of how software works. They are white-box tests. One way isn’t strictly better than the other since each gives you a different path to make your code more reliable.</p>
</li>
</ul>
<p>Not everything is so black and white or as we’d say in the coding world, binary. As an IT specialist, you may need to test that software written by others behaves the way you expect it to. To do this, you can use the combination of black-box and white-box test.</p>
<h3 id="other-test-types">Other Test Types</h3>
<p>When we looked at unit tests, we call out they should focus on one specific unit, a functional method that being tested. This allows the test to verify the unit provides expected functionality regardless of the rest of the environment. On the other hand, integration tests verify that the interactions between the different pieces of code in integrated environments are working the way we expect them to. While unit tests shouldn’t cross boundaries to do things like make a network request or integrate with an API or database, the goal of an integration test is to verify these kinds of interactions and make sure the whole system works how you expect it to.</p>
<ul>
<li>
<p><strong>Integration tests</strong>, usually take the individual modules of code that unit test verify then combine them into a group to test. Depending on what our program does, and how it interacts with the rest of the systems involved, we might need to create a separate test environment for our test. Which runs a test version of our software that we’re trying to verify. We might be able to run our test against the actual version of our system that’s running, but that’s only if our code doesn’t make any changes to the production environment. Whenever your company is deploying a system that’s somewhat complex, having integration tests will help make sure that all the pieces come together the way you expect them to. These tests usually take a bit more work to set up because you’ll need to make sure that you have the test versions of all relevant systems. But they might help catch issues that unit tests won’t text, so the extra effort is definitely worth it. For example, if the service you’re trying to test interacts with a database, you want to set up a separate test database with a test user and a test tables. This lets you run all tests you need in an environment that you can control without risking modifying the production database.</p>
</li>
<li>
<p>A variant of unit tests are <strong>regression tests</strong>. They’re usually written as part of a debugging and troubleshooting process to verify that an issue or error has been fixed once it’s been identified. Say our script has a bug and we’re trying to fix it. A good approach to doing this would be the first right to test fails by triggering the buggy behavior, then fix the bug so that a test passes. Regression tests are useful part of a test suite because they ensure that the same mistake doesn’t happen twice. The same bug can’t be reintroduced into the code because introducing it will cause the regression test to fail.</p>
</li>
<li>
<p><strong>Smoke tests</strong> sometimes called <strong>build verification test</strong>, get their name from a concept that comes from testing hardware equipment. Plug in the given piece of hardware and see if smoke starts coming out of it. When writing software smoke test serve as a kind of sanity check to find major bugs in a program. Smoke test answer basic questions like, does the program run? These tests are usually run before more refined testing takes place. Since if the software fails the smoke test you can be pretty sure none of the other tests will pass either. As they say where there’s smoke there’s fire. For a web service the smoke test would be to check if there’s a service running on the corresponding port. For an automation script, the smoke test would be to run it manually with some basic input and check that the script finishes successfully.</p>
</li>
<li>
<p>Other types of tests are <strong>load tests</strong>. These tests verify that the system behaves well when it’s under significant load. To actually perform these tests will need to generate traffic to our application simulating typical usage of the service. These tests can be super-helpful when deploying new versions of our applications to verify that performance does not degrade. For example, we might want to measure the response time of our website while there are 100 requests per second on our pages, or a 1000, or 10,000. The actual numbers will depend on the expectations of how much traffic our website will receive.</p>
</li>
</ul>
<p>Taking together a group of tests of one or many kinds is commonly referred to as a <strong>test suite</strong>. A good diversity of test types can create a more robust test suite that helps ensure your scripts and automation, do what you tell them to. There are many more kinds of tests out there, we’ve only touched on a few of the most common types. If you’re interested in learning more about the way software can break and how to test for that, all kinds of books and articles have been written on the subject.</p>
<h3 id="test-driven-development">Test-Driven Development</h3>
<p>You might expect that most testing happens after the code has been written. This seems like a natural progression. First you write your script then you write tests that verify that the script does what you want it to do. But this isn’t always the best approach.</p>
<p>A process called <strong>test-driven</strong> or <strong>TDD</strong> calls for creating the test before writing the code. This might seem a bit counter-intuitive, but it can make for more thoughtful well-written programs. When presented with a new problem that can be solved by automation, your gut instinct might be to fire up your code editor and start writing.</p>
<p>But creating some tests first make sure that you’ve thought about the problem that you’re trying to solve and some different approaches that you might use to accomplish it. Writing a test first also helps you think about the ways your program could fail and break which can lead to some valuable insights and even change the approach you take for the better.</p>
<p>The test-driven development cycle typically involves first writing a test then running it to make sure it fails. After all, you haven’t written the code to make it passed yet. Once you’ve verified it fails, you write the code that will satisfy the test then run the tests again. If it passes you can continue on to the next part of your program. If it fails you Debug and run the test again. The cycle is repeated for each new feature of your script until it’s up and running. So before you write your next Python program, you might want to think about the tests you can create to make sure it’s working as you expect.</p>
<p>There are all resources out there if you’d like to learn more about how you can create code using the test-driven development approach. Lots of them are Python-centric, but the principles can be applied to any language you need to create in.</p>
<p>Hopefully you can see the benefits of writing tests to validate the code rate. You gain some understanding about a different testing techniques available. Remember that good tests help make any automation and script you write more robust, resilient, and less buggy. Having reliable automation makes life better for everyone.</p>
<p>Many companies take testing a step further and combine it with our version control systems and development processes. When engineers submit their code, it’s integrated into the main repository and tests are automatically run against it to spot bugs and errors in a process called <strong>Continuous Integration</strong>. Although useful, setting up a continuous integration process can be a big undertaking. Wew ill talk more about it later. In the meantime, if you use unit tests to validate the code you write, you’re already on your way to a more reliable and robust automation.</p>
<h3 id="more-about-tests">More About Tests</h3>
<p>Check out the following links for more information:</p>
<ul>
<li>
<p><a href="https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/">https://landing.google.com/sre/sre-book/chapters/monitoring-distributed-systems/</a></p>
</li>
<li>
<p><a href="https://landing.google.com/sre/sre-book/chapters/testing-reliability/">https://landing.google.com/sre/sre-book/chapters/testing-reliability/</a></p>
</li>
<li>
<p><a href="https://testing.googleblog.com/2007/10/performance-testing.html">https://testing.googleblog.com/2007/10/performance-testing.html</a></p>
</li>
<li>
<p><a href="https://www.guru99.com/smoke-testing.html">https://www.guru99.com/smoke-testing.html</a></p>
</li>
<li>
<p><a href="https://www.guru99.com/exploratory-testing.html">https://www.guru99.com/exploratory-testing.html</a></p>
</li>
<li>
<p><a href="https://testing.googleblog.com/2008/09/test-first-is-fun_08.html">https://testing.googleblog.com/2008/09/test-first-is-fun_08.html</a></p>
</li>
</ul>
<h2 id="errors-and-exceptions">Errors and Exceptions</h2>
<h3 id="the-try-except-construct">The Try-Except Construct</h3>
<p>Along our journey learning Python, we’ve encountered errors generated by the interpreter a bunch of times. We’ve seen examples of TypeError, IndexError, ValueError, and others. Up to now whenever the interpreter threw one of these errors we changed our code to avoid the error. That’s a common approach since whenever the interpreter raises one of these errors the program stops, and we don’t want our scripts to come to an end before they’re done doing their work.</p>
<p>Sometimes it’s easier to make a verification with the conditional to avoid the error. Other times there are so many things that could go wrong that checking for all of them becomes challenging.</p>
<p>Say you had a function that opened a file and did some processing on it. What if the file doesn’t exist? What if the user doesn’t have permissions to read the file? Or what if the file is locked by different process and can’t be opened right now? We could check all of these conditions but what if there’s yet another thing that could cause the open function to raise an error. In a case like this, a better approach is to use the try-except construct.</p>
<p>Let’s look at how it works in an example:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>

<span class="token keyword">def</span> <span class="token function">character_frequency</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Counts the frequency of each character in a given file"""</span>
  <span class="token comment"># First try to open the file</span>
  <span class="token keyword">try</span><span class="token punctuation">:</span>
    f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span>
  <span class="token keyword">except</span> OSError<span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>

  <span class="token comment"># Now process the file</span>
  characters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
  <span class="token keyword">for</span> char <span class="token keyword">in</span> line<span class="token punctuation">:</span>
    characters<span class="token punctuation">[</span>char<span class="token punctuation">]</span> <span class="token operator">=</span> characters<span class="token punctuation">.</span>get<span class="token punctuation">(</span>char<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>

f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">return</span> characters

</code></pre>
<p>Our character_frequency function here reads the contents of a file to count the frequency of each character in them. To do that, the first step is to open the file. In this example, we’ve put the call to the open function inside a try-except block. What this does is first try to do the operation that we want which in this case is to open the file. If there’s an error, it then goes into the accept part of the block that matches the error and does whatever cleanup is necessary. Here we have only one except block, for the OSError error type, but there could be more blocks if the functions called could raise other types of errors.</p>
<p>So when writing a try-except block, the important thing to remember is that <strong>the code in the except block is only executed if one of the instructions in the try block raise an error of the matching type</strong>.</p>
<p>In this case, in the except-block, we’re returning none to indicate to the calling code that the function wasn’t able to do what was requested of it. Returning none when something fails is a common pattern but not the only one. We could also decide to set a variable to some base value like zero for numbers, empty string for strings, empty list for list, and so on. It all depends on what our function does and what we need to get that work done.</p>
<p>The important point is that when we have an operation that might raise an error we want handle that failure gracefully by using the try-except block. The operation could be opening a file, converting a value to a different format, executing a system command, sending data over the network or any other action that might fail and isn’t trivial to check with a conditional.</p>
<p>To use a try-except block, we need to be aware of the errors that functions that we’re calling might raise. This information is usually part of the documentation of the functions. Once we know this we can put the operations that might raise errors as part of the try block, and the actions to take when errors are raised as part of a corresponding except block.</p>
<h3 id="raising-errors">Raising Errors</h3>
<p>We looked into how to handle errors when they’re raised by the functions that we call. In some cases, we might want to raise an error ourselves. This usually happens when some of the conditions necessary for a function to do its job properly aren’t met and returning none or some other base value isn’t good enough.</p>
<p>Let’s look at this through an example. Say we had a function that verifies whether a chosen username is valid. One of the checks this function does is verify that the provided name is at least a certain amount of characters with the minimum value received by a parameter.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>

<span class="token keyword">def</span> <span class="token function">validate_user</span><span class="token punctuation">(</span>username<span class="token punctuation">,</span> minlen<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>username<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token builtin">min</span> <span class="token builtin">len</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token boolean">False</span>
  <span class="token keyword">if</span> <span class="token operator">not</span> username<span class="token punctuation">.</span>isalnum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token boolean">False</span>
  <span class="token keyword">return</span> <span class="token boolean">True</span>
</code></pre>
<p>This code works as long as the provided values are sensible. What would happen if the minlen variable is zero or negative number? Our function will allow an empty username as valid which doesn’t make much sense.</p>
<p>To prevent this from happening, we can add an extra check to our function which will verify the receipt parameters are sane. In this case, returning false would be misleading because it’s not necessarily that the username is invalid but the provided minlen value doesn’t make sense. So let’s add a check to verify that minlen is at least one and raise an error if that’s not the case.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>

<span class="token keyword">def</span> <span class="token function">validate_user</span><span class="token punctuation">(</span>username<span class="token punctuation">,</span> minlen<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">if</span> minlen <span class="token operator">&lt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"minlen should be at least 1"</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>username<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token builtin">min</span> <span class="token builtin">len</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token boolean">False</span>
  <span class="token keyword">if</span> <span class="token operator">not</span> username<span class="token punctuation">.</span>isalnum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token boolean">False</span>
  <span class="token keyword">return</span> <span class="token boolean">True</span>
</code></pre>
<p>As you can see, the keyword to generate an error in Python is <strong>raise</strong>. We can raise a bunch of different errors that come already pre-built with Python or we can create our own, if the standard ones aren’t good enough. In this case, we’re raising a <strong>value error</strong>, a type of error that we’ve come across before to indicate that there was a problem with one of the values of the parameters.</p>
<p>What if instead of passing the string we pass something different as a username to validate?</p>
<p><strong>It’s usually the responsibility of whoever is calling a function to call it the right parameters</strong>. But in some cases, we might want to do this explicitly by checking that we’re receiving a value that makes sense to that function.</p>
<p>So let’s look at an alternative to the raise keyword that we can use for situations where we want to check that our code behaves the way it should particularly when we want to avoid situations that should never happen. This is the <strong>assert</strong> keyword. This keyword tries to verify that a conditional expression is true, and if it’s false it raises an <strong>assertion error</strong> with the indicated message. Let’s add an assertion to our function.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>

<span class="token keyword">def</span> <span class="token function">validate_user</span><span class="token punctuation">(</span>username<span class="token punctuation">,</span> minlen<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">assert</span> <span class="token builtin">type</span><span class="token punctuation">(</span>username<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token string">"username must be a string"</span>
  <span class="token keyword">if</span> minlen <span class="token operator">&lt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"minlen should be at least 1"</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>username<span class="token punctuation">)</span> <span class="token operator">&gt;</span> minlen<span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token boolean">False</span>
  <span class="token keyword">if</span> <span class="token operator">not</span> username<span class="token punctuation">.</span>isalnum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token boolean">False</span>
  <span class="token keyword">return</span> <span class="token boolean">True</span>
</code></pre>
<p>We’ve added an assertion that verifies that the type of the username variable is STR which we know is a name that the interpreter uses for strings. If the function is called with a username parameter that’s not a string, an error will be raised with the message we provided.</p>
<p>As we’ve called out, we usually don’t need to check the types of our parameters. Depending on what our function does, it might be perfectly okay for it to allow scripts to call it with parameters of different types. Assertions can be super helpful for debugging some code that’s not behaving the way we expect it to. We can add them at any point where we want to ensure that the variables contain the values and types that they should or when we think that’s something that shouldn’t happen is happening.</p>
<p><strong>Heads up though</strong>: <em>Assertions will get <strong>removed</strong> from our code if we ask the interpreter to optimize it to run faster</em>.</p>
<p>So as a rule, we should use <strong>raise</strong> to check for conditions that we expect to happen during normal execution of our code and <strong>assert</strong> to verify situations that aren’t expected but that might cause our code to misbehave.</p>
<h3 id="testing-for-expected-errors">Testing for Expected Errors</h3>
<p>we looked into how we can create unit tests for our functions, for both the basic cases and the edge cases. We called out that we should try to cover lots of different possible cases. To make sure that our function behaves correctly in all of them. With some edge cases, like negative value of minlen in our earlier example, the expectation is that the function will raise an error and we want to be able to test that too. So, how do we do that? Well, we use the <em><strong>assertRaises</strong> method</em> provided by the unit test module. Let’s check this out by adding a couple of test cases to the test suite for our validate user function:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>

<span class="token keyword">import</span> unittest

<span class="token keyword">from</span> validate_user <span class="token keyword">import</span> validate_user

<span class="token keyword">class</span> <span class="token class-name">TestValidateUser</span><span class="token punctuation">(</span>unittest<span class="token punctuation">.</span>TestCase<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">test_valid</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    self<span class="token punctuation">.</span>assertEqual<span class="token punctuation">(</span>validate_user<span class="token punctuation">(</span><span class="token string">"validuser"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">test_too_short</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    self<span class="token punctuation">.</span>assertEqual<span class="token punctuation">(</span>validate_user<span class="token punctuation">(</span><span class="token string">"inv"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">test_invalid_characters</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    self<span class="token punctuation">.</span>assertEqual<span class="token punctuation">(</span>validate_user<span class="token punctuation">(</span><span class="token string">"invalid_user"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># Run the tests</span>
unittest<span class="token punctuation">.</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>See [Handling ErrorsCheat-Sheet](Handling Errors Cheat-Sheet.html)</p>
<h2 id="bash-scripting">Bash Scripting</h2>
<h3 id="basic-linux-commands">Basic Linux Commands</h3>
<p>We’ve already used a bunch of Linux commands by now. So hopefully these commands aren’t too foreign. You may remember that <strong>echo</strong> is a command used to print messages to the screen, <strong>cat</strong> is command for showing contents of files, <strong>ls</strong> is the command to list contents of a directory, <strong>chmod</strong> is a command to change permissions of a file, and so on. As we call that before, a lot of these commands come from Unix. Back in the 70s, when designing how these programs should behave, the philosophy was <strong>that they should do one thing and do it very well</strong>. Which means we have a lot of commands, each for doing specific thing.</p>
<ul>
<li>
<p>To create a new directory, we use the <strong>mkdir</strong> command. To change into that directory, we use the <strong>cd</strong> command. As you might notice, these commands don’t print anything to the screen. This is normal and to be expected. A lot of the commands that we’d use don’t print anything when they succeed. They only print something if they fail. To check that the <strong>cd</strong> command succeeded, we can use a command like <strong>pwd</strong> to print the current working directory. We have a directory which is empty. We can copy files using the <strong>cp</strong> command.</p>
</li>
<li>
<p>Lets’ call the command <strong>ls</strong> with the <strong>-la arguments</strong>. Remember, command-line arguments let us change the behavior of commands making them do what we want.</p>
</li>
</ul>
<p>What are all those dots? These are shortcuts that we can use to refer to some special directories. But dot-dot shortcut reverses a parent directory, the previous directory and the absolute path while the dot shortcut reverses the current directory. The dot shortcut, for the current directory, and a dot dot shortcut for the parent directory.</p>
<p>What are these columns? The first column indicates the permissions of the file. The second column is the number of i nodes that point to the file. The third and fourth columns indicate the owner and the group to which the file belongs. Then comes the size of the file that they’ve less modification and finally, the name.</p>
<ul>
<li>
<p>To rename or move a file, we use the mv command.</p>
</li>
<li>
<p>To delete these files, we can use a rm command. We can either go one-by-one or we delete them all together using the star. The star is a placeholder that gets swapped<br>
out by the names of all the files in our directory. We can delete a directory using <strong>rmdir</strong>. This command only works on empty directories so I wouldn’t work if we had left any files in it.</p>
</li>
</ul>
<p>That was a quick overview of some of the commands we have in Linux to operate with files and directories. There are tons of other commands to talk about. Make sure to investigate and practice using all on your own. Remember that reading the documentation, for any given system command, can help you learn more about what it does. On Unix-based systems, this documentation can usually be found in manual or man pages using the <strong>man</strong> command.</p>
<h3 id="redirecting-streams">Redirecting Streams</h3>
<p>So now that we’ve covered a few basic Linux commands, let’s talk more about what we can do with I/O streams and Bash. We talked earlier about the standard I/O streams. By default, the input is provided by the keyboard at the text terminal and the output and error are shown on the screen. This is the case not only for our Python scripts, but for all system commands.</p>
<p>We can change this default using the process called redirection. Redirection is a process of sending a stream to a different destination. This process is provided to us by the operating system and can be really useful when you want to store the output of a command in a file, instead of just looking at it on a screen. To redirect the standard output of a program to a file we use the greater than <strong>&gt;</strong> symbol.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python 3</span>
<span class="token comment"># Script name: stdout_example.py</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Don't mind me, just a bit of text here..."</span><span class="token punctuation">)</span>
</code></pre>
<p>If we run this program without redirection the text will be sent to the display using the <strong>STDOUT</strong> normally. But now if we use a greater than character to redirect the output instead something else happens entirely.</p>
<pre class=" language-bash"><code class="prism  language-bash">$ ./stdout_example.py <span class="token operator">&gt;</span> newfile.txt
$
</code></pre>
<p>When you run it this way the STD out from stdout_example.py script is redirected to a file called new_file.txt. If that file doesn’t exist, it’s created. Let’s look at the contents new_file.txt using the cat command:</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">cat</span> newfile.txt
Don't mind me, just a bit of text here<span class="token punctuation">..</span>.
</code></pre>
<p>Beware, just like we saw earlier with the w file mode used by the open function each time we perform of redirection of STD out, the destination is overwritten.</p>
<p>So we need to be super careful when using this redirection that we’re not overwriting a file with valuable contents.</p>
<p>If we want to <strong>append</strong> the redirected standard out to a file we can use the double greater than sign &gt;&gt; instead of single greater than.</p>
<p>In a similar way we can also redirect standard input. Instead of using the keyboard to send data into a program, we can use the less than symbol to read the contents of a file. Let’s try this out with a new version of the <a href="http://streams.py">streams.py</a> file that we saw in earlier and redirect the contents of our new file to this script:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python 3</span>

data <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"This will come from STDIN: "</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Now we write it to STDOUT: "</span> <span class="token operator">+</span> data<span class="token punctuation">)</span>
<span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Now we generate an error to STDERR"</span><span class="token punctuation">)</span>
</code></pre>
<pre class=" language-bash"><code class="prism  language-bash">$ ./streams_err.py <span class="token operator">&lt;</span> newfile.txt
This will come from STDIN: Now we <span class="token function">write</span> it to STDOUT: Don't mind me, just a bit of text here<span class="token punctuation">..</span>.
Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:
  File <span class="token string">"./streams_err.py"</span>, line 5, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>
    raise ValueError<span class="token punctuation">(</span><span class="token string">"Now we generate an error to STDERR"</span><span class="token punctuation">)</span>
ValueError: Now we generate an error to STDERR
</code></pre>
<p>In this case, we don’t see the input on the screen in the STDIN portion. This is expected because the input was read from a file. So it only appears in the STDOUT portion where we see that it read one of the two lines. This is also expected because the input function only reads until it encounters a new line character.</p>
<p>It can also be useful to redirect STD_err or to capture errors and diagnostic messages from a program. This can be done by using the character combination <strong>2&gt;</strong> than similar to how we redirected STD out before. Let’s execute our stream example again, this time redirecting the err output to a separate file.</p>
<pre class=" language-bash"><code class="prism  language-bash">$ ./streams_err.py <span class="token operator">&lt;</span> newfile.txt 2<span class="token operator">&gt;</span> errorfile.txt
This will come from STDIN: Now we <span class="token function">write</span> it to STDOUT: Don't mind me, just a bit of text here<span class="token punctuation">..</span>.
$ <span class="token function">cat</span> errorfile.txt
Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:
  File <span class="token string">"./streams_err.py"</span>, line 5, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>
    raise ValueError<span class="token punctuation">(</span><span class="token string">"Now we generate an error to STDERR"</span><span class="token punctuation">)</span>
ValueError: Now we generate an error to STDERR
</code></pre>
<p>So this time we don’t see the error message on the screen. That’s because we redirected it to the error file.</p>
<p>If you’re wondering about the number 2, it represents the file descriptor of the STDErr stream. In this context you can think of a file descriptor as a kind of variable pointing to an IO resource. In this case the STDErr stream. 0 and 1 are the file descriptors for STDIN and STDOUT.</p>
<p>Like we call it out already. None of this is exclusive the python we can operate in the same way with all other commands. For example We can create a file using the <strong>echo</strong> command and redirecting its output to the file that we want to create.</p>
<h3 id="pipes-and-pipelines">Pipes and Pipelines</h3>
<p>On top of the redirection to and from files that we saw earlier, there’s another powerful way to perform IO stream redirection called <strong>Piping</strong>. Using <strong>pipes</strong>, you can connect multiple scripts, commands, or other programs together into a data processing pipeline.</p>
<p>Pipes connect the output of one program to the input of another in order to pass data between them. This means we can pass data between programs, taking the output of one and making it the input of the next. Pipes are represented by the pipe character <strong>|</strong>. Using pipes is an extremely useful tool. It allows us to create new commands by combining the functionality of one command, with the functionality of another without having to store the contents in an intermediate file. So let’s work on our plumbing, shall we?</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">ls</span> -l <span class="token operator">|</span> <span class="token function">less</span>
<span class="token punctuation">..</span>.
</code></pre>
<p>The list of files generated by ls is piped to less, which displays them one page at a time. We can scroll up or down using the page up, page down, or arrow keys. Once we’re done looking at the files, we can quit with Q.</p>
<p>But it doesn’t have to stop there. It’s possible to connect a lot more than just two programs using pipes. We’ll check this out using a more elaborate example:</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">cat</span> spider.txt <span class="token operator">|</span> <span class="token function">tr</span> <span class="token string">' '</span> <span class="token string">'\n'</span> <span class="token operator">|</span> <span class="token function">sort</span> <span class="token operator">|</span> <span class="token function">uniq</span> -c <span class="token operator">|</span> <span class="token function">sort</span> -nr <span class="token operator">|</span> <span class="token function">head</span>
   7 the
   3 up
   3 spider
   3 and
   2 rain
   2 climbed
   2 came
   2 bitsy
   1 waterspout.
   1 washed
</code></pre>
<p>That’s a complex command line. Let’s go through it step by step. We’re first using <strong>cat</strong> to get the contents of our spider.txt file. Those contents are then sent to a command called <strong>tr</strong>, which gets its name from the word translate. It takes the characters in the first parameter, in this case, it’s a space and then transform them into a character in the second parameter. In this case, it’s a newline character. So basically, what we’re doing is putting each word in its own separate line. Hurrah for organization. Next, we pass results to the <strong>sort</strong> command through a pipe. This command sorts results alphabetically. The sorted results are then passed to the <strong>uniq</strong> command, which displays each match once, and by using a -c flag, it prefixes each unique line with a number of times it occurred. This output is passed via pipe to the <strong>sort</strong> command once more, this time, with the -nr flag, which sorts results numerically and in reverse order, from most to least hits. The output is finally passed to the <strong>head</strong> command, which prints the first 10 lines to STDOUT.</p>
<p>That’s a lot of process, but when you break it down, it makes lot of sense, right? The point isn’t to memorize all these commands, but to know that we can pipe as many commands as we need to do exactly what we want.</p>
<p>You can use your Python scripts and pipelines too. Python can read from standard input using the <strong>stdin</strong> file object provided by the <strong>sys</strong> module. This is a file object like the one we obtained using the open function, and like your local library, this file object is already open for reading. Let’s say we want to write a script that reads each line of the input and then prints a line with the first character in uppercase. To do this, we’ll take advantage of the capitalize string method:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>
<span class="token comment"># Script name: capitalize.py</span>

<span class="token keyword">import</span> sys

<span class="token keyword">for</span> line <span class="token keyword">in</span> sys<span class="token punctuation">.</span>stdin<span class="token punctuation">:</span>
  <span class="token keyword">print</span><span class="token punctuation">(</span>line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">cat</span> haiku.txt <span class="token operator">|</span> ./capitalize.py
Advance your career,
Automating with python,
It's so fun to learn.
</code></pre>
<p>We don’t need to use a pipe to  get the contents of the Haiku.txt file into standard input of our script. Instead, we use the redirection operator we saw earlier:</p>
<pre class=" language-bash"><code class="prism  language-bash">$ ./capitalize.py <span class="token operator">&lt;</span> haiku.txt
Advance your career,
Automating with python,
It's so fun to learn.
</code></pre>
<p>As a rule, if you just need to get something from standard input into your script, using a redirection is enough. But if you want this to be part of a bigger pipeline of commands, you’ll need to combine them with pipes.</p>
<p>For example, if we only want to capitalize the lines that match a certain pattern, we could first call <strong>grep</strong> and then connect it with the pipe to our scripts.</p>
<p>With a little practice, creating pipelines is a fast and powerful way to perform lots of system administration tasks. When a system command doesn’t exist with the functionality that you need, you can write a Python script to fill in the gap and include it in your pipeline. Understanding how to redirect IO streams can come in handy in many situations and when writing code too.</p>
<h3 id="signalling-processes">Signalling Processes</h3>
<p>When dealing with the operating system, we usually have a bunch of different processes that we use to accomplish what we want. And like any well oiled machine, we generally need these processes to communicate with each other. For example, we might have a program that starts a background process and wants it to terminate after a timeout. One way of communicating this is through the pipelines we learned about in the last video. Another way of communicating is through the use of signals.</p>
<p><strong>Signals</strong> are tokens delivered to running processes to indicate a desired action. Using signals, we can tell a program that we want it to pause or terminate. We can also cause it to reload its configuration, or to close all open files.</p>
<p>Knowing how to send these signals lets us interact with processes and have more control over how they behave. There are a bunch of different ways that we can send these signals. For example, let’s execute the <strong>ping</strong> command in our terminal.</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">ping</span> www.example.com
PING www.example.com <span class="token punctuation">(</span>93.184.216.34<span class="token punctuation">)</span>: 56 data bytes
<span class="token punctuation">..</span>.
</code></pre>
<p>The ping command is now running, sending ICMP packets to machine over the network once per second. And it will keep running forever unless we interrupt it. To do that, we can use the Ctrl-C combination. hen we interrupt it, the program doesn’t just end abruptly. First it prints a summary of what it did and what the results were. It’s very polite under these circumstances. What’s happening behind the scenes is the process received a signal indicating that we wanted it to stop. When that signal’s received, the process does whatever it needs to finish cleanly. The signal that control see sense is called <strong>SIGINT</strong>. It’s just one of many signals that we can send.</p>
<p>Another keyboard combination that we can use to send a signal is <em>Ctrl-Z</em>. Let’s try this one out:</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">ping</span> www.example.com
PING www.example.com <span class="token punctuation">(</span>93.184.216.34<span class="token punctuation">)</span>: 56 data bytes
<span class="token punctuation">[</span><span class="token punctuation">..</span>.<span class="token punctuation">]</span>
zsh: suspended <span class="token function">ping</span> www.example.com
</code></pre>
<p>This time the process didn’t finish properly. We get a message saying that it’s stopped. What’s going on? The signal that we sent is called <strong>SIGSTOP</strong>. This signal causes the program to stop running without actually terminating. But don’t worry, we can make it run again by executing <strong>fg</strong>.</p>
<p>The fg command makes our program run once more and will keep going until we interrupt it either with Ctrl-C, Ctrl-Z, or some other signal. Let’s stop it now with Ctrl-C. By pressing Ctrl-C this time, we’ve made the program finish cleanly.</p>
<p>To send other signals, we can use the command called <strong>kill</strong>. By default, Kill will send a signal called <strong>SIGTERM</strong> that tells the program to terminate. Since Kill is a separate program, we need to run it on a separate terminal. And we also need to know the <strong>process identifier or PID</strong> of the process that we want to send the signal to. To find out the PID that we want to send the signal to, we’ll use the <strong>ps</strong> command which list the currently running processes. Depending on what options that we pass, it’ll show different subsets of processes with different amounts of detail. For this example, we’ll call ps ax, which lists all the running processes in the current computer. And then we’ll use the grep command to only keep lines that contain the name of the process that we’re looking for:</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">ping</span> www.example.com
PING www.example.com <span class="token punctuation">(</span>93.184.216.34<span class="token punctuation">)</span>: 56 data bytes
<span class="token punctuation">..</span>.
</code></pre>
<p>From another terminal:</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">ps</span> ax <span class="token operator">|</span> <span class="token function">grep</span> <span class="token function">ping</span>
46024 s000  R      0:00.00 <span class="token function">grep</span> <span class="token function">ping</span>
46011 s001  S+     0:00.01 <span class="token function">ping</span> www.example.com
$ <span class="token function">kill</span> 46011
</code></pre>
<p>We’ve now sent the <strong>SIGTERM</strong> signal and the process was terminated. Hasta la vista process. Notice how in this case, we didn’t get the nice summary at the end, the program just finished.</p>
<p>As you might expect, there is more signals that we can send and they might cause programs to react differently. Many long running programs, for example, will reload their configuration from disk if we send them a signal. This way we can let the program know that there’s an important change in the configuration and it can get applied without the program having to stop to reread it. Programs that provide web services may also receive a signal to tell them that they should finish dealing with any currently open connections and then terminate cleanly once it’s done. Understanding what these signals are and how to send them will let you interact with the processes on your system that you’re in charge of and make them behave as you want.</p>
<p>See <a href="Basic_Linux_Commands_Cheat-Sheet.html">Basic Linux Commands Cheat-Sheet</a> &amp; <a href="Redirections_Pipes_and_Signals.html">Redirections, Pipes and Signals</a></p>
<h2 id="scripting-with-bash">Scripting with Bash</h2>
<h3 id="creating-bash-scripts">Creating Bash Scripts</h3>
<p>We mentioned in earlier videos that bash is the most commonly used shell on Linux. <strong>Bash</strong> is not only the interpreter that runs our commands, it’s also a <em>scripting language</em>. We can use Bash to write simple scripts when we need to use a lot of commands.</p>
<p>Let’s start with an example of why you would even want to do this. In your job as an IT specialist, you sometimes need to debug a computer that’s not behaving correctly. There are lots of commands that can tell you what’s going on in there to help you with your debugging. For example, the <strong>ps</strong> command can list all the current running processes. The <strong>free</strong> command can show you the amount of free memory. The <strong>uptime</strong> command can tell you how long the computer has been on and so on. Anytime you need to debug a computer, you can manually run these commands one by one, followed by as many commands as you can think of that might be helpful. But that already sounds tedious just describing it.</p>
<p>What if instead, you can run a single command that can gather all these information in just one shot? Well, I have some good news for you. We can do this by creating a Bash script that contains all of the commands that we want to call, one after the other:</p>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token shebang important">#!/bin/bash</span>
<span class="token comment"># Script name: gather_information.sh</span>
<span class="token keyword">echo</span> <span class="token string">"Starting at: <span class="token variable"><span class="token variable">$(</span><span class="token function">date</span><span class="token variable">)</span></span>"</span>
<span class="token keyword">echo</span>

<span class="token keyword">echo</span> <span class="token string">"UPTIME"</span>
<span class="token function">uptime</span>
<span class="token keyword">echo</span>

<span class="token keyword">echo</span> <span class="token string">"FREE"</span>
<span class="token function">free</span>
<span class="token keyword">echo</span>

<span class="token keyword">echo</span> <span class="token string">"WHO"</span>
<span class="token function">who</span>
<span class="token keyword">echo</span>

<span class="token keyword">echo</span> <span class="token string">"Finishing at: <span class="token variable"><span class="token variable">$(</span><span class="token function">date</span><span class="token variable">)</span></span>"</span>
</code></pre>
<p>The script we’re seeing here is calling three main <strong>commands</strong>, <strong>uptime</strong>, <strong>free</strong>, and who, which lists users currently logged into the computer. It uses the <strong>echo</strong> command to print some other information and to make the output a bit more readable by leaving empty lines between the commands. We’re also calling the <strong>date</strong> command to print the current date. To call this command, we’re using a <em>special notation</em> by putting the command inside dollar sign parentheses. This indicates that the output of the command should be passed to the echo command and be printed to the screen.</p>
<p>As the script is written right now, there’s one command per line. That’s a common practice, but it’s not the only way. We could also write the commands on the same line using semicolons <strong>;</strong> to separate them.</p>
<h3 id="using-variables-and-globs">Using Variables and Globs</h3>
<p>Like we said earlier, bash is a fully powered scripting language, not just a way of executing commands one after the other. We can assign variables, conditional operations, execute loops, defined functions, and so much more. So much that will only get to cover the very basics in these next few videos. Let’s start with variables. Much like Python, bash lets us use variables to store and retrieve values.</p>
<p>Heads up: there can be <strong>no spaces between the name of the variable and the equal sign</strong>, or between the equal sign and the value. If we try to define a variable and leave a space at one side or the other, the show will complain that it can’t find the command with the name that we’re assigning.</p>
<pre class=" language-bash"><code class="prism  language-bash">$ example<span class="token operator">=</span>hello
$ <span class="token keyword">echo</span> <span class="token variable">$example</span>
hello
</code></pre>
<p>Also remember that any variable that you define in your script or in the command line is local to the environment where you define it. If you want commands from that environment to also see the variable you need to export them using the <strong>export</strong> keyword. Now, let’s modify our script to gather info and add a variable to it. We’ll use it to make our script look nicer by adding lines in between each of the commands. To do this, we’ll define a variable called line, and we’ll put a bunch of dashes in it.</p>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token shebang important">#!/bin/bash</span>
<span class="token comment"># Script name: gather_information.sh</span>
line<span class="token operator">=</span><span class="token string">"------------------------------"</span>
<span class="token keyword">echo</span> <span class="token string">"Starting at: <span class="token variable"><span class="token variable">$(</span><span class="token function">date</span><span class="token variable">)</span></span>"</span><span class="token punctuation">;</span> <span class="token keyword">echo</span> <span class="token variable">$line</span>

<span class="token keyword">echo</span> <span class="token string">"UPTIME"</span><span class="token punctuation">;</span> <span class="token function">uptime</span><span class="token punctuation">;</span> <span class="token keyword">echo</span> <span class="token variable">$line</span>

<span class="token keyword">echo</span> <span class="token string">"FREE"</span><span class="token punctuation">;</span> <span class="token function">free</span><span class="token punctuation">;</span> <span class="token keyword">echo</span> <span class="token variable">$line</span>

<span class="token keyword">echo</span> <span class="token string">"WHO"</span><span class="token punctuation">;</span> <span class="token function">who</span><span class="token punctuation">;</span> <span class="token keyword">echo</span> <span class="token variable">$line</span>

<span class="token keyword">echo</span> <span class="token string">"Finishing at: <span class="token variable"><span class="token variable">$(</span><span class="token function">date</span><span class="token variable">)</span></span>"</span>
</code></pre>
<p>Let’s move on to another interesting feature available in bash called <strong>globs</strong>. Globs are characters that allow us to create list of files. The star <strong>*</strong> and question mark <strong>?</strong> are the most common globs. Besides being extremely fun to say globs, using these globs lets us create <em>sequences of filenames that we can use as parameters to the commands we call an our scripts</em>. You’ve probably come across them before, but let’s do a quick recap of how we can use them.</p>
<ul>
<li>
<p>In bash, using a star in the command line we’ll match all filenames that follow the format that we specify. A star with no prefix or suffix would match all the files in the current directory.</p>
</li>
<li>
<p>Alternatively, the question mark symbol can be used to match exactly one character instead of any amount of characters, and we can repeat it as many times as we need. For example, we can get the Python files with five characters in their name by using the five question marks together.</p>
</li>
</ul>
<p>Using globs like this&nbsp;lets us create list of files that we might operate on,&nbsp;like calling other commands in passing this list.&nbsp;If you want to use this functionality in Python, it’s available through the glob module.</p>
<h3 id="conditional-execution-in-bash">Conditional Execution in Bash</h3>
<p>One of the main concepts of programming is being able to branch the execution according to a condition. In other words, making our program behave in different ways depending on one or more values.</p>
<p>In Python, we use the if block and the condition is an expression that has to evaluate to true or false.</p>
<p>In Bash scripting, the condition used is based on the exit status of commands. Reminder: we can check the exit status for command using the dollar sign question mark <strong>$?</strong>. And in Bash scripting an exit value of zero means success. This logic is used by the if operator in bash.</p>
<p>To create a conditional expression, we’re going to call a command and if the exit status of that command is zero, then the condition will be considered true. Say we wanted to verify that the /etc/hosts file contains an entry for 127.0.0.1, which it should. Knowing that grep will return it exit status of zero when it finds at least one match and different than zero if it doesn’t find a match, we can use it to do this verification.</p>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token shebang important">#!/bin/bash</span>
<span class="token comment"># Script name: check_localhost.sh</span>

<span class="token keyword">if</span> <span class="token function">grep</span> <span class="token string">"127.0.0.1"</span> /etc/hosts<span class="token punctuation">;</span> <span class="token keyword">then</span>
  <span class="token keyword">echo</span> <span class="token string">"Everything ok"</span>
<span class="token keyword">else</span>
  <span class="token keyword">echo</span> <span class="token string">"ERROR! 127.0.0.1 is not in /etc/hosts"</span>
<span class="token keyword">fi</span>
</code></pre>
<p>Let’s test it:</p>
<pre class=" language-bash"><code class="prism  language-bash">$ ./check_localhost.sh
127.0.0.1       localhost
Everything ok
</code></pre>
<p>So our script said that everything was okay. If <strong>grep</strong> hadn’t found that line, it would have exited with a value different than zero and we would’ve received a different message. There is plenty of other conditions that we might want to check in our scripts, if the file exists, if two strings are equal, if a number is less than another number, and so on. To help us with evaluating these conditions, there is a command called <strong>test</strong>.</p>
<p>Test is a command that evaluates the conditions received and exits with zero when they are true and with one when they’re false.</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token keyword">if</span> <span class="token function">test</span> -n <span class="token string">"<span class="token variable">$PATH</span>"</span><span class="token punctuation">;</span> <span class="token keyword">then</span> <span class="token keyword">echo</span> <span class="token string">"Your PATH is not empty"</span><span class="token punctuation">;</span> <span class="token keyword">fi</span>
Your PATH is not empty
</code></pre>
<p>We’re using the -n option for the test command, which checks if a string variable is empty or not. In this case, path is an empty, so we get the message. Using the test command like this is so common, there’s another way of writing it, which looks more like other programming languages. It’s something like this:</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token keyword">if</span> <span class="token punctuation">[</span> -n <span class="token string">"<span class="token variable">$PATH</span>"</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span> <span class="token keyword">echo</span> <span class="token string">"Your PATH is not empty"</span><span class="token punctuation">;</span> <span class="token keyword">fi</span>
Your PATH is not empty
</code></pre>
<p>In this case, the command we’re calling is the opening square bracket. This is an <em>alias</em> to the <strong>test</strong> command, but to call it successfully, we also need to include a closing square bracket. <strong>When using this syntax, remember that there needs to be a space before the closing bracket</strong>.</p>
<p>There’s plenty of other things that we can check with test, but we won’t cover them here. We’ll include some of them in the upcoming cheat sheet and<br>
you can also see all of them by looking at the manual page for test.</p>
<h3 id="bash-scripting-resources">Bash Scripting Resources</h3>
<p>Check out the following links for more information:</p>
<ul>
<li>
<p><a href="https://ryanstutorials.net/bash-scripting-tutorial/">https://ryanstutorials.net/bash-scripting-tutorial/</a></p>
</li>
<li>
<p><a href="https://linuxconfig.org/bash-scripting-tutorial-for-beginners">https://linuxconfig.org/bash-scripting-tutorial-for-beginners</a></p>
</li>
<li>
<p><a href="https://www.shellscript.sh">https://www.shellscript.sh</a></p>
</li>
</ul>
<h2 id="advanced-bash-concepts">Advanced Bash Concepts</h2>
<p>Bash provides similar looping structures to Python. We can iterate while a condition is true using a <em>while loop</em> and iterate over a list of elements using a <em>for loop</em>. Although of course, the syntax for these loops is slightly different.</p>
<h3 id="while-loops-in-bash-scripts">While Loops in Bash Scripts</h3>
<p>Let’s check out a simple while loop in Bash. The condition for the while loop usesthe same format as a condition for an if block. The loop itself starts with the do keyword and finishes with a done keyword. To increment the value of the variable n, we’re using a bash construct of double parentheses that lets us do arithmetic operations with our variables:</p>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token shebang important">#!/bin/bash</span>

n<span class="token operator">=</span>1
<span class="token keyword">while</span> <span class="token punctuation">[</span> <span class="token variable">$n</span> -le 5<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">do</span>
    <span class="token keyword">echo</span> <span class="token string">"Iteration number <span class="token variable">$n</span>"</span>
    <span class="token variable"><span class="token punctuation">((</span>n<span class="token operator">+</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">))</span></span>
<span class="token keyword">done</span>
</code></pre>
<p>So that works but what about making our loop a bit more interesting. When using while loops and bash scripts, it’s common to have a loop that retries a command a number of times until it succeeds. This is really useful with commands that use network connections or that access resources that might be locked. These commands can fail for external reasons and they’re likely to succeed after a retry or two.</p>
<p>To simulate a command that sometimes succeeds or sometimes fails, we have a small Python script that will return an exit value picked at random by a range that we give it:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>
<span class="token comment"># Script name:random-exit.py</span>

<span class="token keyword">import</span> sys
<span class="token keyword">import</span> random

value <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Returning: "</span> <span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">)</span>
sys<span class="token punctuation">.</span>exit<span class="token punctuation">(</span>value<span class="token punctuation">)</span>
</code></pre>
<p>Let’s trun the simulation:</p>
<pre class=" language-bash"><code class="prism  language-bash">$ ./retry.sh ./random-exit.py
Returning: 1
Retry <span class="token comment">#1</span>
Returning: 2
Retry <span class="token comment">#2</span>
Returning: 0
</code></pre>
<h3 id="for-loops-in-bash-scripts">For Loops in Bash Scripts</h3>
<p>Both in Python and Bash, <em>for loops</em> are used to iterate over a sequence of elements. You might remember that the key to for loops is that they let us perform an operation on each of the elements in a sequence.</p>
<ul>
<li>
<p>In Python, the sequences are data structures like a list or a tuple or a string.</p>
</li>
<li>
<p>In Bash, we construct these sequences just by listing the elements with spaces in between. Let’s check this out using a very simple example:</p>
</li>
</ul>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token shebang important">#!/bin/bash</span>
<span class="token comment"># Script name: fruits.sh</span>
<span class="token keyword">for</span> fruit <span class="token keyword">in</span> peach orange apple<span class="token punctuation">;</span> <span class="token keyword">do</span>
    <span class="token keyword">echo</span> <span class="token string">"I like <span class="token variable">$fruit!</span>"</span>
<span class="token keyword">done</span>
</code></pre>
<p>Let’s use a practical example to see this in action. Imagine that you’re migrating your company’s website from one web server software to another. Your web content is stored in a bunch of files that all end in uppercase HTM, and the new software requires that they all end in lowercase html, disaster!</p>
<p>You can manually rename them one by one using the MV command, but that could get really old really fast. You’d likely end up making mistakes after the first few commands. Instead, you could do the same thing with short Bash script.</p>
<p>First, let’s check out our files.</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">cd</span> old_website
$ <span class="token function">ls</span> -l
-rwx------@ 1 user  staff  0 Jan  9 12:26 about.HTM
-rwx------@ 1 user  staff  0 Jan  9 12:26 contact.HTM
-rwx------@ 1 user  staff  0 Jan  9 12:26 footer.HTM
-rwx------@ 1 user  staff  0 Jan  9 12:26 header.HTM
-rwx------@ 1 user  staff  0 Jan  9 12:26 index.HTM
</code></pre>
<p>Looks like we have five files that we need to rename. So how can we extract the part before the extension? There’s a command called <strong>basename</strong> that can help us with that. This command takes a filename and an extension and then returns the name without the extension. Just like that, we’re ready to write our script and rename the files.</p>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token shebang important">#!/bin/bash</span>

<span class="token keyword">for</span> <span class="token function">file</span> <span class="token keyword">in</span> *.HTM<span class="token punctuation">;</span> <span class="token keyword">do</span>
    name<span class="token operator">=</span><span class="token punctuation">$(</span>basename <span class="token string">"<span class="token variable">$file</span>"</span> .HTM<span class="token punctuation">)</span>
    <span class="token keyword">echo</span> <span class="token function">mv</span> <span class="token string">"<span class="token variable">$file</span>"</span> <span class="token string">"<span class="token variable">$name</span>.html"</span> <span class="token comment">#prefixing mv with echo for testing purposes</span>
<span class="token keyword">done</span>
</code></pre>
<p>We’re surrounding our file variable with double-quotes to allow the command to work even if the file has spaces in its name. This is a good practice in Bash scripts when dealing with file names or any variables that could include spaces</p>
<p>We’ll then call the <strong>mv</strong> command with the old and new names. In this case, we use double quotes for both parameters. Again, we want to make sure that it works correctly for file names with spaces, and that’s all that our loop needs to do. We’ll finish our loop of the done keyword, and we’re done, almost.</p>
<p>We still need to run our script to see if it does what it should. Now, let me share a trick with you that might save you a few headaches. <strong>Whenever you’re going to run a script like this that modifies the files in your file system, it’s a really good idea to first run it without actually modifying the file system</strong>. This will catch any possible bugs that the script might have.</p>
<p>So instead of just running it as it is right now, we’ll add an echo in front of the MV command. This means that instead of actually renaming, our script we’ll print the renaming that it plans to do.</p>
<p>Hopefully by now, you’re starting to see how you can benefit from using Bash scripts when dealing with files and system commands, especially to compliment your Python scripts.</p>
<h3 id="advanced-command-interaction">Advanced Command Interaction</h3>
<p>We’ve learned a lot about how to do things in the Linux command line and in Bash scripts. We will now look at a couple of interesting applications for all these Bash scripting powers that we just learned to put all this new knowledge into action. Let’s go back to our old friend, the system log file located in var/log/syslog. The system log file contains a trove of information about what’s going on in the system. So it’s really important to learn how to get information out of it.</p>
<p>Let’s use the tail command to look at the last 10 lines from the file right now.</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">tail</span> /var/log/syslog
<span class="token punctuation">[</span><span class="token punctuation">..</span>.<span class="token punctuation">]</span>
</code></pre>
<p>The load lines we see follow a similar pattern. First, they include the date and time of when the entry was added to the file, then the name of the computer, then the name and PID of the process that trigger the event and finally, the actual event that’s being logged. Take a second and look at those lines. Say that we had a computer that was under significant load but we didn’t know why, and to find out we wanted to check what events are being logged the most to our Syslog. To do that we need to extract the part of the line that has the actual event without the date and time. We can use a command called <strong>cut</strong> to help us with that. This command, let’s us take only bits of each line using a field delimiter. In this example, we can split the line using spaces. That would look something like this.</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">tail</span> /var/log/syslog <span class="token operator">|</span> <span class="token function">cut</span> -d<span class="token string">' '</span> -f5-
<span class="token punctuation">[</span><span class="token punctuation">..</span>.<span class="token punctuation">]</span>
</code></pre>
<p>In our example, we’re passing -d’ ’ to <strong>cut</strong> to tell it that we want to use a space as a delimiter, and -f5- that tell it that we want to print the field number 5 and everything that comes after it. With that, we remove the date and the name of the computer keeping only the process and the event message. Now that we have the information that we care about, we can pipe this to the same pipeline of commands that we saw earlier to find out the lines that are repeated the most, like this:</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">cut</span> -d<span class="token string">' '</span> -f5- /var/log/syslog <span class="token operator">|</span> <span class="token function">sort</span> <span class="token operator">|</span> <span class="token function">uniq</span> -c <span class="token operator">|</span> <span class="token function">sort</span> -nr <span class="token operator">|</span> <span class="token function">head</span>
<span class="token punctuation">[</span><span class="token punctuation">..</span>.<span class="token punctuation">]</span>
</code></pre>
<p>There are more files in var/log that we might be interested in. So we can use a <em>for loop</em> to iterate over each of the log files in var/log and get the most repeated lines in each of them.</p>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token shebang important">#!/bin/bash</span>
<span class="token comment"># Script name: toploglines.sh</span>

<span class="token keyword">for</span> logfile <span class="token keyword">in</span> /var/log/*log<span class="token punctuation">;</span> <span class="token keyword">do</span>
    <span class="token function">cut</span> -d<span class="token string">' '</span> -f5- <span class="token variable">$logfile</span> <span class="token operator">|</span> <span class="token function">sort</span> <span class="token operator">|</span> <span class="token function">uniq</span> -c <span class="token operator">|</span> <span class="token function">sort</span> -nr <span class="token operator">|</span> <span class="token function">head</span> -5
<span class="token keyword">done</span>
</code></pre>
<h3 id="choosing-between-bash-and-python">Choosing Between Bash and Python</h3>
<p>As you can probably tell by now, there’s a lot of interesting things that we can do with the system commands. We’ve come across a bunch of different commands that can help us operate with files and processes, and get more information about the computer, process the contents of files, and all sorts of other things. By using bash scripts, we can very quickly turn a command that operates on just one file into an automated script that handles 1,000 files. Pretty powerful, right? As we saw with our log file examples, there’s a bunch of terminal commands that provide text processing functionality.</p>
<p>Plenty of them also support regular expressions, allowing us to do some very advanced processing of the data in our files. When these commands are linked together in a data processing pipeline, they can become a powerful tool for processing text data. They can give us information we’re looking for quickly about the need to write a full script.</p>
<p>But you know what they say about great power? We need to be careful not to abuse this because it can quickly become unreadable.</p>
<p>Compare:</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token variable"><span class="token variable">$(</span><span class="token function">cat</span> story.txt<span class="token variable">)</span></span><span class="token punctuation">;</span> <span class="token keyword">do</span> B<span class="token operator">=</span><span class="token string">'echo -n "<span class="token variable">${i:0:1}</span>" | tr "[:lower:]" "[:upper:]"'</span><span class="token punctuation">;</span> <span class="token keyword">echo</span> -n <span class="token string">"<span class="token variable">${B}</span><span class="token variable">${i:1}</span> "</span><span class="token keyword">:</span> <span class="token keyword">done</span><span class="token punctuation">;</span> <span class="token keyword">echo</span> -e <span class="token string">"\n"</span>
Once Upon A Time There Was An Egg Of A Programming Language Called Python
</code></pre>
<p>with:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment">#!/usr/bin/env python3</span>
<span class="token comment"># Script name: capitalyze_words.py</span>
<span class="token keyword">import</span> sys

<span class="token keyword">for</span> line <span class="token keyword">in</span> sys<span class="token punctuation">.</span>stdin<span class="token punctuation">:</span>
  words <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>word<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> words<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Once we have the script, we can execute it as part of a pipeline like this:</p>
<pre class=" language-bash"><code class="prism  language-bash">$ <span class="token function">cat</span> story.txt <span class="token operator">|</span> ./capitalize_words.py
Once Upon A Time There Was An Egg Of A Programming Language Called Python
</code></pre>
<p>So it’s a good idea to choose bash when we’re operating with files and system commands, as long as what we’re doing is simple enough that the script is self-explanatory.</p>
<p>As soon as it becomes hard to understand what the script is doing, it’s better to write it in a more general scripting language like Python. Bash scripts aren’t as flexible or robust as having entire Python language available, with its many functions to operate on strings, lists, and dictionaries.</p>
<p>There’s another gotcha when it comes to bash and Linux commands, and it’s something that we’ve said before. Their availability depends on the platform that we’re using. Some commands might not be present on certain operating systems. Running a bash script can get the job done very quickly on a Linux machine, but it won’t work on a Windows machine. There, we need to write the same script in PowerShell. So if the tasks that you’re trying to accomplish is limited to the current server or a fleet of servers, all running the same operating system, a simple bash script can get the job done. But if your code is complex or it needs to work across platforms, you might be better off using the Python standard library or other external modules that provide the same functionality.</p>
<p>Last thing, there are lots of situations where either a bash script or a Python script might solve the problem just fine. In those cases, you can choose whichever one you feel more comfortable with.</p>
<h2 id="final-project">Final Project</h2>
<p>Well, here we are. We’re finally at the last module of the course. Congratulations on making it all the way here. It’s been a long and challenging road and hopefully you’re now feeling confident about automating system task through Python. Great work. Along our journey, we’ve become much more familiar with lots of tools that Python has to offer.</p>
<p>We’ve learned about managing files and directories, reading and writing both text files and CSV files using regular expressions, understanding how the system interacts to our programs, executing system commands, and writing automated test to name a few. We’ve even learned a bit about different scripting language called Bash.</p>
<h3 id="writing-a-script-from-the-ground-up">Writing a Script from the Ground Up</h3>
<p>Whenever you’re tackling a project that requires coding like writing a small script to automate a single task or writing a large programming project that handles a lot of information, there’s a process that we recommend that you follow. We looked at this already in the first course of the program, but let’s go over it once again to have it fresh in our minds. Things run much smoother when you remember to check all the boxes.</p>
<ol>
<li>
<p>The first step to handle any coding project is to fully understand the <strong>problem statement</strong>. This includes: spelling out what needs to be done and identifying what the given inputs and desired outputs are for that program that we need to write.</p>
</li>
<li>
<p>After that, we recommend doing some <strong>research</strong>. This means figuring out how we can tackle the problem by the tools provided by the Python standard library or by external modules. Remember, we want to avoid reinventing the wheel. No matter how tricky and intricate the challenge appears, chances are that others have solved something similar before. Coding is a bit like Hollywood. There are not that many new ideas, mostly re-imaginings. So it’s valuable that we spent some time looking into what resources exist to help us solve our problem. This research phase also includes looking at the documentation of the modules, classes, and functions that we’ll need to use, and understanding how they should be applied. A lot of the documentation also includes examples. So it’s helpful to absorb those and see how they relate to the code that we need to write.</p>
</li>
<li>
<p>Once we know what we need to write and what tools we can use to make it work, we should do some <strong>planning</strong>. This means thinking about what data types are useful for our solution, the order of operations that we need to perform, and how all the pieces have come together to form our solution. Synergy. If the problem is complex, it might help to write down the plan for quick reference, either on a piece of paper or in a digital document. Writing down the plan helps us focus on how we’re going to do things and identify any problems our plan might have. At many companies, it’s a common practice to write a design document at this stage, detailing the problem statement, the tools that will be used to solve it, and the plan of attack towards a solution. Having others comment on your design helps make sure that all the twists have been untangled.</p>
</li>
<li>
<p>Finally, once we have a clear plan, we do the actual <strong>writing</strong> of the script. This step includes not only writing the code, but also checking that the code does what it’s supposed to do. We do that by both manually testing the code and adding some automatic test. Sometimes, it’s tempting to just jump right into the coding stage, about spending any necessary time to fully understand the problem, research tools, or plan the solution. But our experience shows us spending a while getting familiar with what we’re trying to do and what tools we have available to do it can make a big difference. Both in how long it takes to do the actual implementation and ultimately how well our solution behaves.</p>
</li>
</ol>
<p>So practice following this process as you dig into the final course project, and then try to apply this to any coding projects that you might tackle in the future.</p>
<h3 id="problem-statement-2">Problem Statement #2</h3>
<p>Imagine a scenario, one of the servers used by your company runs a service called Ticky. This service is an internal ticketing system used by a lot of different teams in the company to manage their work. The service logs a bunch of events to syslog, both when it runs successfully and when it encounters errors. Developers of the service are asking for your help with getting some information out of those logs, to better understand how the software is being used and how to improve it.</p>
<p>No sweat. As an up and coming IT Professional, you enthusiastically accept this mission. So for your final project in this course, you’ll write some automation scripts that will process the system log and generate a bunch of reports based on the information extracted from log files. The log lines follow a pattern similar to the ones we’ve seen before. Something like this:</p>
<pre class=" language-text"><code class="prism  language-text">May 27 11:45:40 ubuntu.local ticky: INFO: Created ticket [#1234] (username)
Jun 1 11:06:48 ubuntu.local ticky: ERROR: Connection to DB failed (username)
</code></pre>
<p>When the service runs correctly, it logs an info message to syslog, stating what it’s done, the username, and the ticket number related to the event. If the service encounters a problem, it logs in error message to the syslog, indicating what was wrong and the username that triggered the action that caused the problem.</p>
<p>The developers of the service want two different reports out of this data.</p>
<ol>
<li>
<p>The first one is a ranking of errors generated by the system. This means a list of all error messages logged, and how many times each of them was found, not taking into account the users involved. They should be sorted by the most common error to the least common error.</p>
</li>
<li>
<p>The second one is a usage statistics for the service. This means, a list of all users that have used the system including how many info messages and how many error messages they’ve generated. This report should be sorted by username.</p>
</li>
</ol>
<ul>
<li>
<p>To visualize the data in these reports, you want to generate a couple of webpages that’ll be served by a web server running on the machine. To do this, you can make use of a script that’s already in the system called csv_ to_html.py. This script converts the data in a CSV file into an HTML file containing a table with the data.</p>
</li>
<li>
<p>Then, put the files in the directory that’s used by the webserver to display the webpages. The goal is to have one script that can get all the necessary work done automatically, every day without any user interaction. This script doesn’t need to do all the work itself. It can call on other scripts to do individual task and then put the results together. In fact, we recommend splitting the task so that each piece can be written and tested separately.</p>
</li>
</ul>
<p>I imagine that your mind is racing, your pulse might have spread up a little bit, and your palms are sweating all over the keyboard. Don’t worry. This might sound like a lot of work. But once you’ve understood the problem and done some research and planning, everything will start to fall into place. In our next video, we’ll give you some tips on how to start breaking this task down. Here we go.</p>
<h3 id="help-with-research-and-planning">Help with Research and Planning</h3>
<p>We’ve now gone over the problems statement of our final project. At first sight, it might sound pretty complex. But let’s break it down into smaller more digestible pieces and discuss how we can move into the next steps to do the necessary research and planning.</p>
<p>We’ve said that we want to find some specific log lines in the syslog file. We strongly recommend that you use regular expressions to find them. It’ll be easier to extract information you want that way. To figure out the right regular expression, you can use a website like <a href="https://regex101.com">regex101.com</a> which can help you test your expression and understand what’s going on with it. Once you have a pattern that you think and work, try it out in a Python interpreter to verify that it matches the right lines and captures the right information.</p>
<p>After extracting the information, you’ll need to count how many errors are of the same type, and how many info and error messages there are for a given user. Can you think of what data structure might help you with that? If you’re thinking dictionaries, then you’re on the right track. You’ll want to use a couple of different dictionaries. One to account error messages and another to count per user usage. You’ll then need to sort the data in a dictionary’s by different criteria. We looked at sorting in the Introduction to Python course. Feel free to re-watch that video and reread the Python documentation on sorting.</p>
<p>The output of your Python script should be a couple of CSV files. Each of them containing the names of the columns and the data in the order that it needs to be presented. Once those files are generated, you’ll need to call the csv_to_html.py script to create HTML files based on CSV data. You’ll have access to look at how the script works but the key is to pass two parameters to it. The name of the CSV file to read and the name of the HTML file generate. You could do this last step from either a Python script or a bash script. Since the script will be only calling commands and moving files, we recommend doing a bash. Keep it short and sweet.</p>
<p>We recommend that you research, plan and even write the pieces of code all before starting the actual lab. Good luck. You’ve got it!</p>
<blockquote>
<p>Written with <a href="https://stackedit.io/">StackEdit</a>.</p>
</blockquote>

    </div>
  </div>
</body>

</html>
